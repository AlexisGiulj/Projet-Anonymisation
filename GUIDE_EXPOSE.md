# Guide pour votre ExposÃ© sur l'Anonymisation de Graphes

## ğŸ“‹ RÃ©sumÃ© de ce qui a Ã©tÃ© crÃ©Ã©

Vous disposez maintenant d'une **application complÃ¨te de dÃ©monstration** qui implÃ©mente et compare les **5 types de mÃ©thodes d'anonymisation de graphes** prÃ©sentÃ©s dans la thÃ¨se de NGUYEN Huu-Hiep.

### Fichiers gÃ©nÃ©rÃ©s :

1. **graph_anonymization_demo.py** (630 lignes) - Application principale
2. **README.md** - Documentation complÃ¨te du projet
3. **GUIDE_EXPOSE.md** (ce fichier) - Guide pour votre prÃ©sentation
4. **requirements.txt** - DÃ©pendances Python

### Visualisations gÃ©nÃ©rÃ©es :

1. **graph_anonymization_comparison.png** (3.3 MB) - Comparaison visuelle des 7 variantes
2. **degree_distributions.png** (574 KB) - Distributions des degrÃ©s
3. **metrics_comparison.png** (443 KB) - MÃ©triques quantitatives

---

## ğŸ¯ Les 5 Types de MÃ©thodes ImplÃ©mentÃ©es

### 1. Anonymisation par Randomisation ğŸ²

**Principe** : Modifier alÃ©atoirement la structure du graphe

**Deux variantes testÃ©es** :
- **Random Add/Del** : Ajoute 5 arÃªtes, supprime 5 arÃªtes
  - RÃ©sultat sur Karate Club : 78 arÃªtes (identique)
- **Random Switch** : Ã‰change 10 paires d'arÃªtes
  - RÃ©sultat : 78 arÃªtes (degrÃ©s prÃ©servÃ©s)

**Points pour l'exposÃ©** :
- MÃ©thode la plus simple mais pas de garantie formelle
- Random Switch prÃ©serve les degrÃ©s mais pas les chemins
- UtilisÃ©e dans : Hay et al. (2008), Ying & Wu (2008)

---

### 2. K-Anonymisation ğŸ”’

**Principe** : Garantir que chaque nÅ“ud est indistinguable d'au moins k-1 autres

**Variante testÃ©e** :
- **k-degree anonymity** (k=3)
  - RÃ©sultat : 92 arÃªtes (ajout de 14 arÃªtes)

**Points pour l'exposÃ©** :
- Protection formelle contre attaques par degrÃ©s
- Doit ajouter/supprimer des arÃªtes de maniÃ¨re dÃ©terministe
- NP-difficile en gÃ©nÃ©ral
- UtilisÃ©e dans : Liu & Terzi (2008), Zhou & Pei (2008)

---

### 3. GÃ©nÃ©ralisation ğŸŒ

**Principe** : Regrouper les nÅ“uds en "super-nÅ“uds"

**Variante testÃ©e** :
- **Clustering** (taille minimale k=3)
  - RÃ©sultat : 3 super-nÅ“uds (au lieu de 34 nÅ“uds)

**Points pour l'exposÃ©** :
- RÃ©duction drastique de la taille : 34 â†’ 3 nÅ“uds
- Forte protection mais perte d'information importante
- Produit un graphe agrÃ©gÃ©, pas le graphe original
- UtilisÃ©e dans : Hay et al. (2008), Campan & Truta (2008)

---

### 4. Approches Probabilistes ğŸ¯

**Principe** : CrÃ©er un "graphe incertain" avec probabilitÃ©s sur les arÃªtes

**Variante testÃ©e** :
- **(k,Îµ)-obfuscation** (k=3, Îµ=0.1)
  - RÃ©sultat : 316 arÃªtes (dont beaucoup avec faible probabilitÃ©)

**Points pour l'exposÃ©** :
- ModÃ©lise explicitement l'incertitude
- Permet l'Ã©chantillonnage de graphes compatibles
- Bon compromis privacy/utilitÃ©
- UtilisÃ©e dans : Boldi et al. (2012), Mittal et al. (2013)

---

### 5. Privacy DiffÃ©rentielle ğŸ›¡ï¸

**Principe** : Garantie mathÃ©matique formelle (Îµ-differential privacy)

**Deux variantes testÃ©es** :
- **EdgeFlip** (Îµ=1.0)
  - RÃ©sultat : 208 arÃªtes (inversion probabiliste)
- **Laplace Mechanism** (Îµ=0.5)
  - RÃ©sultat : 225 arÃªtes (ajout de bruit)

**Points pour l'exposÃ©** :
- Garanties thÃ©oriques les plus fortes
- ComposabilitÃ© des mÃ©canismes
- Pas d'hypothÃ¨ses sur l'attaquant
- Trade-off : Îµ faible = haute privacy mais basse utilitÃ©
- UtilisÃ©e dans : Dwork (2011), Sala et al. (2011), Xiao et al. (2014)

---

## ğŸ“Š RÃ©sultats ObservÃ©s

### Nombre d'arÃªtes (graphe original : 78)

| MÃ©thode | ArÃªtes | Variation |
|---------|--------|-----------|
| Random Add/Del | 78 | 0% |
| Random Switch | 78 | 0% |
| k-degree (k=3) | 92 | +18% |
| GÃ©nÃ©ralisation | 3 super-nÅ“uds | N/A |
| (k,Îµ)-obf | 316 | +305% |
| EdgeFlip (Îµ=1.0) | 208 | +167% |
| Laplace (Îµ=0.5) | 225 | +188% |

**Observations clÃ©s** :
- Random Switch prÃ©serve parfaitement le nombre d'arÃªtes ET les degrÃ©s
- k-anonymity ajoute peu d'arÃªtes (+18%)
- MÃ©thodes probabilistes et DP ajoutent beaucoup d'arÃªtes (pour crÃ©er de l'incertitude)
- GÃ©nÃ©ralisation compresse radicalement le graphe

---

## ğŸ¤ Structure SuggÃ©rÃ©e pour l'ExposÃ© (30-35 min)

### Introduction (5 min)

**Slide 1 : Titre**
- Titre : "Ã‰tat de l'Art de l'Anonymisation de Graphes Sociaux"
- Sous-titre : "Revue basÃ©e sur la thÃ¨se de NGUYEN Huu-Hiep (2016)"
- Votre nom

**Slide 2 : Contexte**
- Explosion des rÃ©seaux sociaux (Facebook, Twitter, LinkedIn...)
- Big Data : besoin de partager les donnÃ©es pour la recherche
- ProblÃ¨me : protÃ©ger la vie privÃ©e des utilisateurs

**Slide 3 : Le ProblÃ¨me**
- Montrer l'exemple de la Figure 1.1 de la thÃ¨se
- Attaque par rÃ©-identification basÃ©e sur les degrÃ©s
- L'anonymisation naÃ¯ve (suppression des IDs) ne suffit PAS

**Question rhÃ©torique** : "Comment publier des graphes sociaux tout en protÃ©geant la vie privÃ©e ?"

---

### Les 5 Familles de MÃ©thodes (20 min - 4 min par mÃ©thode)

**Pour chaque mÃ©thode :**

1. **Principe** (30 sec)
   - Une phrase simple pour expliquer l'idÃ©e

2. **Exemple visuel** (1 min 30)
   - Montrer la comparaison Original vs AnonymisÃ©
   - Pointer les diffÃ©rences visuelles

3. **RÃ©sultats quantitatifs** (1 min)
   - Montrer les mÃ©triques (nb arÃªtes, degrÃ©s, clustering...)
   - InterprÃ©ter les changements

4. **Avantages / InconvÃ©nients** (1 min)
   - Forces et faiblesses de l'approche
   - Quand l'utiliser ?

**Ordre suggÃ©rÃ© :**
1. Randomisation (la plus simple)
2. K-anonymisation (garantie formelle)
3. GÃ©nÃ©ralisation (approche radicale)
4. Probabiliste (compromis)
5. Privacy DiffÃ©rentielle (gold standard actuel)

---

### Comparaison et Discussion (7 min)

**Slide : Tableau Comparatif**

| CritÃ¨re | Randomisation | K-anonymity | GÃ©nÃ©ralisation | Probabiliste | Diff. Privacy |
|---------|---------------|-------------|----------------|--------------|---------------|
| **Garantie formelle** | âŒ | âœ… (k-anonymity) | âš ï¸ | âš ï¸ | âœ… (Îµ-DP) |
| **PrÃ©servation utilitÃ©** | âœ… | âœ… | âŒ | âœ… | âš ï¸ |
| **SimplicitÃ©** | âœ… | âš ï¸ | âš ï¸ | âŒ | âš ï¸ |
| **ScalabilitÃ©** | âœ… | âŒ (NP-dur) | âš ï¸ | âš ï¸ | âŒ (O(nÂ²)) |

**Slide : Trade-off Privacy/Utility**
- Montrer le graphique metrics_comparison.png
- Expliquer qu'il y a toujours un compromis
- Plus on protÃ¨ge, plus on distord

**Questions de recherche ouvertes :**
- Comment mesurer prÃ©cisÃ©ment la "privacy" ?
- Peut-on avoir privacy ET utility ?
- Comment adapter Ã  des graphes dynamiques ?
- Nouvelles attaques ?

---

### DÃ©monstration (3 min)

**Option 1 : VidÃ©o**
- Enregistrer un screencast du script qui tourne
- Montrer la gÃ©nÃ©ration des visualisations en temps rÃ©el

**Option 2 : Images**
- Montrer les 3 PNG gÃ©nÃ©rÃ©s
- Zoomer sur des dÃ©tails intÃ©ressants

**Ce qu'il faut montrer :**
1. Le graphe Karate Club original
2. Une transformation visuelle frappante (ex: GÃ©nÃ©ralisation)
3. La comparaison des distributions de degrÃ©s
4. Les mÃ©triques quantitatives

---

### Conclusion (2-3 min)

**Slide : RÃ©capitulatif**
- 5 grandes familles de mÃ©thodes
- Ã‰volution : mÃ©thodes ad-hoc â†’ garanties formelles
- Privacy DiffÃ©rentielle : Ã©tat de l'art actuel

**Slide : Perspectives**
- Graphes dynamiques et streaming
- Graphes avec attributs riches
- Privacy pour d'autres structures (hypergraphes, etc.)
- Applications pratiques (Open Data, partage inter-organisations)

**Slide : Questions**
- "Merci de votre attention"
- Vos coordonnÃ©es ou rÃ©fÃ©rences

---

## ğŸ’¡ Conseils pour la PrÃ©sentation

### Avant l'exposÃ©

âœ… **Testez votre setup**
- VÃ©rifiez que les images s'affichent correctement
- PrÃ©parez un backup PDF de vos slides

âœ… **ChronomÃ©trez-vous**
- RÃ©pÃ©tez votre prÃ©sentation
- Ajustez pour tenir dans le temps imparti

âœ… **Anticipez les questions**
- Voir section "Questions FrÃ©quentes" ci-dessous

### Pendant l'exposÃ©

âœ… **Interaction avec le public**
- Posez des questions rhÃ©toriques
- Demandez : "Qui utilise Facebook ? LinkedIn ?"

âœ… **Storytelling**
- Commencez par une anecdote (ex: le scandale Cambridge Analytica)
- Utilisez des exemples concrets

âœ… **Gestion du temps**
- Gardez un Å“il sur l'horloge
- PrÃ©parez des "slides de backup" qu'on peut sauter si nÃ©cessaire

---

## â“ Questions FrÃ©quentes Ã  Anticiper

### Q1 : "Quelle mÃ©thode est la meilleure ?"

**RÃ©ponse** : Ã‡a dÃ©pend du contexte !
- **Pour la recherche** : Privacy DiffÃ©rentielle (garanties formelles)
- **Pour la publication rapide** : Randomisation (simple et rapide)
- **Pour la protection maximale** : GÃ©nÃ©ralisation (mais perte d'utilitÃ©)
- **Pour le compromis** : Approches Probabilistes

---

### Q2 : "Comment on mesure concrÃ¨tement la 'privacy' ?"

**RÃ©ponse** : Plusieurs mÃ©triques existent :
1. **Min-entropy** : Quantifie la plus grande probabilitÃ© de rÃ©-identification
2. **Shannon entropy** : Mesure l'incertitude globale
3. **Incorrectness** : Nombre de mauvaises suppositions de l'attaquant
4. **Îµ dans DP** : Borne sur le ratio de probabilitÃ©s

Dans notre dÃ©mo, on se concentre sur l'**utilitÃ©** (prÃ©servation de la structure), mais mesurer la privacy rigoureusement nÃ©cessite de simuler des attaques.

---

### Q3 : "Quelle est la diffÃ©rence entre edge-DP et node-DP ?"

**RÃ©ponse** :
- **Edge-DP** : ProtÃ¨ge la prÃ©sence/absence d'une arÃªte
  - Deux graphes voisins diffÃ¨rent par une arÃªte
  - Plus facile Ã  atteindre

- **Node-DP** : ProtÃ¨ge la prÃ©sence/absence d'un nÅ“ud entier
  - Deux graphes voisins diffÃ¨rent par un nÅ“ud et toutes ses arÃªtes
  - Beaucoup plus difficile (sensibilitÃ© = degrÃ© max)

La plupart des mÃ©thodes de la thÃ¨se se concentrent sur **edge-DP**.

---

### Q4 : "Ces mÃ©thodes marchent-elles sur des graphes de millions de nÅ“uds ?"

**RÃ©ponse** : Ã‡a dÃ©pend !
- **Scalables** : Randomisation, k-degree (heuristiques)
- **Moyennement scalables** : Probabilistes, certaines mÃ©thodes DP
- **Pas scalables** : GÃ©nÃ©ralisation (clustering coÃ»teux), EdgeFlip (O(nÂ²))

Les dÃ©fis de **scalabilitÃ©** sont un axe de recherche actif. MÃ©thodes rÃ©centes : HRG-FixedTree, 1K-series (mentionnÃ©s dans la thÃ¨se).

---

### Q5 : "Peut-on appliquer plusieurs mÃ©thodes en sÃ©quence ?"

**RÃ©ponse** : Oui, mais attention !
- Pour la **Privacy DiffÃ©rentielle** : OUI, grÃ¢ce Ã  la composabilitÃ©
  - Îµ_total = Îµâ‚ + Îµâ‚‚ + ... (composition sÃ©quentielle)

- Pour les **autres mÃ©thodes** : Possible mais pas de garantie formelle
  - Peut amÃ©liorer la privacy empiriquement
  - Risque de dÃ©grader davantage l'utilitÃ©

---

### Q6 : "Quels sont les logiciels/librairies disponibles ?"

**RÃ©ponse** :
- **NetworkX** (Python) : Manipulation de graphes, mais pas d'anonymisation intÃ©grÃ©e
- **Google DP Library** : Pour la privacy diffÃ©rentielle gÃ©nÃ©rale
- **OpenDP** : Framework moderne pour DP
- **Implementations acadÃ©miques** : Souvent prototypes dans les papiers

Il n'existe **pas encore** de librairie standard unifiÃ©e pour l'anonymisation de graphes.

---

## ğŸ“ RÃ©fÃ©rences ClÃ©s Ã  Citer

### La ThÃ¨se

**NGUYEN Huu-Hiep** (2016). *Anonymisation de Graphes Sociaux* (Social Graph Anonymization).
ThÃ¨se de doctorat, UniversitÃ© de Lorraine, LORIA.
Directeurs : Abdessamad Imine, MichaÃ«l Rusinowitch.

### Papers Fondateurs (par catÃ©gorie)

**Randomisation :**
- Hay et al. (2008) - Resisting Structural Re-identification
- Ying & Wu (2008, 2011) - Randomizing Social Networks

**K-anonymity :**
- Liu & Terzi (2008) - k-degree Anonymization
- Zhou & Pei (2008) - k-neighborhood
- Zou et al. (2009) - k-automorphism

**GÃ©nÃ©ralisation :**
- Hay et al. (2008) - Generalization Strategy
- Campan & Truta (2008) - Clustering Approach

**Probabiliste :**
- Boldi et al. (2012) - (k,Îµ)-obfuscation
- Mittal et al. (2013) - RandWalk

**Differential Privacy :**
- Dwork (2011) - Algorithmic Foundations of DP
- Sala et al. (2011) - Sharing Graphs using DP Graph Models
- Xiao et al. (2014) - HRG-MCMC

---

## ğŸ“ Organisation des Fichiers pour l'ExposÃ©

```
Votre_Presentation/
â”‚
â”œâ”€â”€ slides.pdf ou slides.pptx        # Vos slides
â”‚
â”œâ”€â”€ images/                           # Dossier d'images
â”‚   â”œâ”€â”€ graph_anonymization_comparison.png
â”‚   â”œâ”€â”€ degree_distributions.png
â”‚   â””â”€â”€ metrics_comparison.png
â”‚
â”œâ”€â”€ demo/                             # Code de dÃ©monstration (optionnel)
â”‚   â”œâ”€â”€ graph_anonymization_demo.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ references/                       # Papiers importants (optionnel)
    â””â”€â”€ Nguyen16_thesis.pdf
```

---

## ğŸš€ Pour Aller Plus Loin (aprÃ¨s l'exposÃ©)

Si vous voulez enrichir la dÃ©monstration :

1. **Ajouter d'autres graphes** :
   - Facebook ego-network
   - Email-Eu-core
   - Ca-GrQc (collaboration)

2. **ImplÃ©menter des mÃ©triques de privacy** :
   - Simuler des attaques de rÃ©-identification
   - Calculer l'incorrectness

3. **Ajouter des visualisations** :
   - DÃ©tection de communautÃ©s avant/aprÃ¨s
   - Heatmap des matrices d'adjacence

4. **CrÃ©er une interface web** :
   - Streamlit ou Plotly Dash
   - Permettre Ã  l'utilisateur de choisir les paramÃ¨tres

---

## âœ… Checklist Finale

**24h avant l'exposÃ©** :
- [ ] Slides finalisÃ©s et testÃ©s
- [ ] Images exportÃ©es en haute rÃ©solution
- [ ] ChronomÃ©trage fait (avec marge de 2-3 min)
- [ ] RÃ©ponses aux questions prÃ©parÃ©es
- [ ] Backup des fichiers sur clÃ© USB + cloud

**Le jour J** :
- [ ] Arriver 15 min en avance
- [ ] Tester vidÃ©oprojecteur/Ã©cran
- [ ] VÃ©rifier le son (si vidÃ©o)
- [ ] Avoir de l'eau Ã  disposition
- [ ] Respirer et sourire ğŸ˜Š

---

## ğŸ“ Besoin d'Aide ?

Si vous avez des questions techniques sur le code :
- Consultez le README.md
- Lisez les commentaires dans graph_anonymization_demo.py
- Testez diffÃ©rents paramÃ¨tres (k, epsilon, etc.)

**Bonne chance pour votre exposÃ© ! ğŸ‰**

---

*Document gÃ©nÃ©rÃ© le 24 novembre 2025*
*BasÃ© sur la thÃ¨se de NGUYEN Huu-Hiep (2016)*
