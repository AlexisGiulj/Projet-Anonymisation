# Changelog - Am√©liorations Majeures de l'Application

**Date** : 24 novembre 2025
**Commit** : 7b9cbd9

## üéØ Vue d'Ensemble

L'application a √©t√© consid√©rablement am√©lior√©e avec de nouvelles fonctionnalit√©s interactives, des simulations d'attaques r√©elles, et un contenu √©ducatif enrichi. Le nombre d'onglets est pass√© de 5 √† 8 pour une meilleure organisation.

---

## üÜï Nouvelles Fonctionnalit√©s

### 1. **Param√®tres de Privacy Modulables** ‚öôÔ∏è

**Avant** : Les param√®tres (k, epsilon) √©taient cod√©s en dur dans le code.

**Maintenant** : Sliders interactifs dans la sidebar permettant d'ajuster :
- **k** (pour Random Add/Del, Random Switch, k-degree anonymity, Generalization, Probabilistic) : 2-50
- **epsilon** (pour EdgeFlip, Laplace, Probabilistic) : 0.1-3.0

**Feedback en temps r√©el** :
- ‚úÖ Privacy Forte (Œµ < 1.0) : Perte ‚â§ e^Œµ
- ‚ö†Ô∏è Privacy Moyenne (1.0 ‚â§ Œµ < 2.0)
- ‚ùå Privacy Faible (Œµ ‚â• 2.0)

### 2. **Nouvelle Structure avec 8 Onglets**

| Onglet | Nouveau/Modifi√© | Contenu |
|--------|-----------------|---------|
| üìä R√©sultats | Inchang√© | Visualisations graphiques comparatives |
| üìñ D√©finitions | **NOUVEAU** | D√©finitions formelles + intuitions pour chaque concept |
| üìà M√©triques Utilit√© | **NOUVEAU** | Densit√©, clustering, diam√®tre, corr√©lation degr√©s |
| üîí M√©triques Privacy | **NOUVEAU** | k-anonymit√©, epsilon, garanties sp√©cifiques |
| üéØ Simulations d'Attaques | **NOUVEAU** | Degree Attack + Subgraph Attack interactives |
| üõ°Ô∏è Attaques & Garanties | D√©plac√© | Protections et vuln√©rabilit√©s par m√©thode |
| üìö Dict. Attaques | **NOUVEAU** | 7 attaques document√©es avec exemples Karate Club |
| üîç Dict. Propri√©t√©s | **NOUVEAU** | 12 propri√©t√©s de graphes expliqu√©es |

### 3. **Onglet D√©finitions** üìñ

Exploration interactive des 5 concepts d'anonymisation :

**Pour chaque concept** :
- üìù **D√©finition Formelle** : Notation math√©matique rigoureuse
- üî¢ **Formule** : Expression math√©matique compl√®te
- üí° **Intuition** : Explication en langage naturel avec analogies
- üîí **Garantie de Privacy** : Promesse formelle offerte
- ‚öôÔ∏è **Signification des Param√®tres** : Interpr√©tation de k, epsilon, etc.

**Exemple pour k-anonymit√©** :
```
D√©finition : ‚àÄv ‚àà V, |{u ‚àà V : deg(u) = deg(v)}| ‚â• k
Intuition : Comme se cacher dans une foule - si k personnes ont la m√™me taille,
            vous ne pouvez pas √™tre distingu√© parmi elles.
Garantie : P(r√©-identification | degr√©) ‚â§ 1/k
```

### 4. **M√©triques d'Utilit√©** üìà

Mesure la pr√©servation de l'utilit√© du graphe :

**M√©triques de Base** :
- Nombre de n≈ìuds/ar√™tes
- Densit√© (avec delta par rapport √† l'original)
- Coefficient de clustering moyen (avec delta)

**M√©triques Globales** :
- Diam√®tre du graphe
- Longueur moyenne des chemins
- Corr√©lation de Spearman des degr√©s (0 = aucune, 1 = parfaite)

**Visualisations** :
- Graphique en barres : Ar√™tes pr√©serv√©es/ajout√©es/supprim√©es
- Barre de progression : Taux de modification
- Feedback color√© :
  - ‚úÖ < 10% : Utilit√© tr√®s bien pr√©serv√©e
  - ‚ÑπÔ∏è 10-30% : Utilit√© correctement pr√©serv√©e
  - ‚ö†Ô∏è > 30% : Modifications importantes

### 5. **M√©triques Privacy** üîí

M√©triques sp√©cifiques √† chaque type de m√©thode :

**k-anonymity** :
- k requis vs ensemble d'anonymat minimum
- Probabilit√© de r√©-identification : P = 1/k
- Indicateur ‚úÖ/‚ùå si k-anonymit√© satisfaite
- Barre de progression du risque

**Differential Privacy (EdgeFlip, Laplace)** :
- Budget epsilon actuel
- Borne de perte : e^Œµ ‚âà X.XX
- Niveau de privacy (Forte/Moyenne/Faible)
- Probabilit√© de flip (EdgeFlip)
- Nombre attendu d'ar√™tes bruit√©es

**Probabilistic (k,Œµ)-obfuscation** :
- Nombre de graphes candidats (k)
- Tol√©rance epsilon
- Entropie minimale : log(k) - Œµ
- Facteur de confusion

**Generalization** :
- Taille min/moy des clusters
- Probabilit√© maximale de r√©-identification
- Ratio intra-cluster/inter-cluster

### 6. **Simulations d'Attaques** üéØ

**Interface Interactive** :
- S√©lection du n≈ìud cible (0 √† n-1)
- Choix du type d'attaque :
  - **Degree Attack** : Recherche par degr√© uniquement
  - **Subgraph Attack** : Recherche par degr√© + triangles

**R√©sultats de Simulation** :
- ‚úÖ/‚ùå Succ√®s ou √©chec de l'attaque
- Explication d√©taill√©e
- Liste des n≈ìuds candidats trouv√©s
- Probabilit√© de succ√®s si ambigu√´ : 1/|candidats|

**Exemple de R√©sultat** :
```
‚ö†Ô∏è R√©-identification ambigu√´ : 3 n≈ìuds ont le degr√© 16.
Probabilit√© de succ√®s : 33.3%

Candidats trouv√©s : [0, 5, 23]
```

**Section √âducative** :
- Explications d√©taill√©es de chaque type d'attaque
- M√©thodes de protection efficaces

### 7. **Dictionnaire des Attaques** üìö

7 attaques document√©es en d√©tail :

| Attaque | S√©v√©rit√© | Protection Efficace |
|---------|----------|---------------------|
| Degree Attack | Moyenne | k-degree anonymity, Randomization |
| Active Attack (Sybil) | √âlev√©e | Differential Privacy |
| Passive Attack (Interne) | Moyenne | Randomization, Generalization |
| Subgraph Attack | √âlev√©e | Generalization, DP |
| Neighborhood Attack | Tr√®s √©lev√©e | Generalization, (k,Œµ)-obfuscation |
| Walk-based Attack | Moyenne | DP sur marches al√©atoires |
| Auxiliary Info Attack | Tr√®s √©lev√©e | Differential Privacy seule |

**Pour chaque attaque** :
- üìù Description d√©taill√©e
- üí° Exemple concret (souvent sur Karate Club)
- ‚ö†Ô∏è Niveau de s√©v√©rit√©
- üõ°Ô∏è M√©thode de protection recommand√©e

**Exemples Concrets sur Karate Club** :
- Sc√©nario d'attaque pas √† pas
- √âtapes d√©taill√©es
- Taux de succ√®s :
  - Sans protection
  - Avec k-anonymity
  - Avec Randomization
  - Avec Differential Privacy
- Code de simulation Python

**Exemple : Degree Attack sur Mr. Hi** :
```
Sc√©nario : L'adversaire sait que Mr. Hi (n≈ìud 0) a 16 connexions

√âtapes :
1. Observer le graphe anonymis√©
2. Chercher le n≈ìud ayant degr√© = 16
3. Si unique ‚Üí R√©-identification r√©ussie !

Taux de succ√®s :
- Sans protection : 100% (degr√© unique)
- Avec k=2 anonymity : ‚â§ 50% (au moins 2 n≈ìuds de degr√© 16)
- Avec randomization : ~40% (degr√© bruit√©)
```

### 8. **Dictionnaire des Propri√©t√©s** üîç

12 propri√©t√©s de graphes expliqu√©es :

| Propri√©t√© | Utilit√© | Privacy Risk |
|-----------|---------|--------------|
| Degr√© | Critique | √âlev√© |
| Clustering Coefficient | √âlev√©e | Moyen |
| Betweenness Centrality | Critique | √âlev√© |
| Closeness Centrality | Moyenne | Moyen |
| Eigenvector Centrality | √âlev√©e | √âlev√© |
| Densit√© | Moyenne | Faible |
| Diam√®tre | Moyenne | Faible |
| Average Path Length | √âlev√©e | Faible |
| Degree Distribution | Critique | Moyen |
| Modularit√© | √âlev√©e | Moyen |
| Triangles | √âlev√©e | Moyen |
| Assortativit√© | Moyenne | Faible |

**Pour chaque propri√©t√©** :
- üìù D√©finition claire
- üî¢ Formule math√©matique
- üí° Exemple concret
- üìä Importance pour l'utilit√© (Critique/√âlev√©e/Moyenne/Faible)
- ‚ö†Ô∏è Risque pour la privacy (√âlev√©/Moyen/Faible)

**Calcul en Temps R√©el** :
- Valeurs calcul√©es pour le graphe actuellement anonymis√©
- Exemples : degr√© moyen, clustering, densit√©, diam√®tre, etc.

---

## üîß Am√©liorations Techniques

### Nouvelles Fonctions Python

**1. `simulate_degree_attack(G_orig, G_anon, target_node=0)`**
- Simule une attaque par degr√©
- Retourne : succ√®s/√©chec, candidats, explication, probabilit√©

**2. `simulate_subgraph_attack(G_orig, G_anon, target_node=0)`**
- Simule une attaque par sous-graphe (triangles)
- Plus sophistiqu√©e que l'attaque par degr√© seul
- Combine degr√© + nombre de triangles

**3. `calculate_utility_metrics(G_orig, G_anon)`**
- Calcule toutes les m√©triques d'utilit√©
- Retourne : densit√©, clustering, diam√®tre, corr√©lation, etc.
- G√®re les graphes non connexes (composante principale)

**4. `calculate_privacy_metrics_separated(G_orig, G_anon, method_key, method_params)`**
- Calcule les m√©triques de privacy sp√©cifiques √† chaque m√©thode
- S√©par√© de calculate_privacy_guarantees pour meilleure organisation
- Retourne : k-value, epsilon, probabilit√©s, etc.

### Gestion des Param√®tres Dynamiques

**Avant** :
```python
G_anon = anonymizer.random_add_del(**method['params'])
```

**Maintenant** :
```python
dynamic_params = {}  # R√©cup√©r√©s des sliders
st.session_state.method_params = dynamic_params
G_anon = anonymizer.random_add_del(**dynamic_params)
```

Les param√®tres sont maintenant :
- Sauvegard√©s dans `st.session_state.method_params`
- Pass√©s aux fonctions de calcul de m√©triques
- Affich√©s dans les onglets pour r√©f√©rence

---

## üìö Contenu √âducatif Enrichi

### D√©finitions Formelles ET Intuitives

**Exemple : Privacy Diff√©rentielle**

**D√©finition Formelle** :
```
Un algorithme A satisfait la Œµ-differential privacy si pour deux graphes
G et G' diff√©rant d'une seule ar√™te, et pour tout r√©sultat O :

P[A(G) = O] ‚â§ e^Œµ √ó P[A(G') = O]
```

**Intuition** :
```
La privacy diff√©rentielle garantit que la pr√©sence ou l'absence d'un individu
change tr√®s peu les r√©sultats. C'est comme ajouter du bruit calibr√© :
un adversaire ne peut pas d√©terminer si vous √™tes dans la base de donn√©es,
m√™me avec une connaissance parfaite de tous les autres.

Le param√®tre Œµ contr√¥le le "budget de privacy" :
- Œµ petit = protection forte, donn√©es bruit√©es
- Œµ grand = protection faible, donn√©es pr√©serv√©es
```

### Exemples Concrets Syst√©matiques

Chaque attaque et propri√©t√© est illustr√©e avec :
- Des cas sur le **graphe Karate Club** (familier √† l'utilisateur)
- Des **valeurs num√©riques r√©elles** (ex: "Mr. Hi a degr√© 16")
- Des **sc√©narios r√©alistes** (ex: "adversaire conna√Æt les connexions")
- Des **taux de succ√®s quantifi√©s** (ex: "95% sans protection, 20% avec")

### Trade-offs Privacy vs Utilit√©

**Visualisations Claires** :
- Graphiques c√¥te √† c√¥te : modifications vs pr√©servation
- Barres de progression : % de modification, % de risque
- Indicateurs color√©s :
  - Vert : Bon √©quilibre
  - Orange : Compromis acceptable
  - Rouge : Trade-off d√©favorable

---

## üìä Statistiques

### Lignes de Code

- **Fichier principal** : graph_anonymization_app.py
  - Avant : ~1,470 lignes
  - Apr√®s : ~2,063 lignes (+593 lignes, +40%)

- **Nouveau fichier** : definitions_and_attacks.py
  - Contenu : ~550 lignes
  - Dictionnaires : 5 concepts + 7 attaques + 12 propri√©t√©s + 3 exemples

### Fonctionnalit√©s

- **Onglets** : 5 ‚Üí 8 (+3 onglets, +60%)
- **Fonctions Python** : 9 ‚Üí 13 (+4 fonctions)
- **Param√®tres modulables** : 0 ‚Üí 7 param√®tres
- **Attaques document√©es** : 0 ‚Üí 7 attaques
- **Propri√©t√©s document√©es** : 0 ‚Üí 12 propri√©t√©s
- **Simulations interactives** : 0 ‚Üí 2 types d'attaques

---

## üöÄ Utilisation

### Lancer l'Application

```bash
cd GraphAnonymizationDemo
streamlit run graph_anonymization_app.py
```

Ou via le lanceur Windows :
```bash
LANCER.bat
# Choisir Option 1
```

### Workflow Recommand√©

1. **Choisir un graphe** (Karate Club recommand√© pour les exemples)
2. **S√©lectionner une m√©thode** d'anonymisation
3. **Ajuster les param√®tres** avec les sliders (epsilon, k)
4. **Anonymiser** et explorer les 8 onglets :
   - üìä Voir les r√©sultats visuels
   - üìñ Comprendre les d√©finitions
   - üìà √âvaluer l'utilit√© pr√©serv√©e
   - üîí Mesurer la privacy obtenue
   - üéØ Tester des attaques r√©elles
   - üõ°Ô∏è V√©rifier les garanties
   - üìö Apprendre sur les attaques
   - üîç Explorer les propri√©t√©s

### Cas d'Usage P√©dagogiques

**Pour un cours** :
1. Montrer l'onglet **D√©finitions** pour introduire les concepts
2. Utiliser l'onglet **Dict. Propri√©t√©s** pour expliquer les m√©triques
3. Lancer une anonymisation et comparer **Utilit√©** vs **Privacy**
4. Simuler des **Attaques** pour illustrer les risques
5. Consulter le **Dict. Attaques** pour voir les protections

**Pour une pr√©sentation** :
1. Commencer par **Karate Club** (graphe familier)
2. Essayer **k=2 degree anonymity** avec le slider
3. Montrer l'onglet **Simulations d'Attaques** : attaquer Mr. Hi (n≈ìud 0)
4. Comparer avec **Differential Privacy** (epsilon=0.5)
5. Re-simuler l'attaque ‚Üí taux de succ√®s diminu√©

---

## üîÑ Comparaison Avant/Apr√®s

| Aspect | Avant | Apr√®s |
|--------|-------|-------|
| **Param√®tres** | Cod√©s en dur | Sliders interactifs |
| **M√©triques** | M√©lang√©es | S√©par√©es Utilit√©/Privacy |
| **Attaques** | Liste statique | Simulations interactives |
| **D√©finitions** | Texte dans code | Onglet d√©di√© avec formules |
| **Propri√©t√©s** | Non document√©es | 12 propri√©t√©s expliqu√©es |
| **Trade-off** | Pas visualis√© | Graphiques et indicateurs |
| **P√©dagogie** | Formules seules | Formules + Intuitions + Exemples |
| **Feedback** | Aucun | En temps r√©el sur epsilon |

---

## üìù Notes de Version

**Version** : 2.0
**Compatibilit√©** : Python 3.8+
**D√©pendances** : Inchang√©es (streamlit, networkx, matplotlib, numpy, scipy)

**Fichiers Ajout√©s** :
- `definitions_and_attacks.py` : Dictionnaires de contenu √©ducatif

**Fichiers Modifi√©s** :
- `graph_anonymization_app.py` : Application principale

**Fichiers Temporaires** (non versionn√©s) :
- `graph_anonymization_app_backup.py` : Backup de l'ancienne version
- `new_tabs_content.py` : Fichier de travail (peut √™tre supprim√©)

---

## üôè Remerciements

Cette mise √† jour majeure a √©t√© r√©alis√©e pour rendre l'application plus **p√©dagogique**, **interactive** et **compl√®te**. Elle est maintenant un v√©ritable **outil d'apprentissage** pour comprendre l'anonymisation de graphes sociaux.

Merci √† NGUYEN Huu-Hiep pour sa th√®se qui a inspir√© cette application.

---

**Pour toute question ou suggestion** : Ouvrir une issue sur GitHub
**Repository** : https://github.com/AlexisGiulj/Projet-Anonymisation
