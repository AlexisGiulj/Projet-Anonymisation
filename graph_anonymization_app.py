"""
Application Interactive d'Anonymisation de Graphes Sociaux
Bas√©e sur la th√®se "Anonymisation de Graphes Sociaux" par NGUYEN Huu-Hiep

Application Streamlit avec s√©lection de m√©thodes et explications d√©taill√©es
"""

import streamlit as st
import networkx as nx
import matplotlib.pyplot as plt
import numpy as np
from collections import Counter
import random
from copy import deepcopy
import io
import pandas as pd
from method_details import ATTACKS_AND_GUARANTEES
from definitions_and_attacks import (
    ANONYMIZATION_DEFINITIONS,
    ATTACKS_DICTIONARY,
    GRAPH_PROPERTIES,
    CONCRETE_ATTACK_EXAMPLES
)

# Configuration de la page
st.set_page_config(
    page_title="Anonymisation de Graphes Sociaux",
    page_icon="üîí",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Style CSS personnalis√©
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 20px;
    }
    .method-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    .metric-box {
        background-color: #e8f4f8;
        padding: 15px;
        border-radius: 5px;
        border-left: 5px solid #1f77b4;
    }
    .math-formula {
        background-color: #fff3cd;
        padding: 10px;
        border-radius: 5px;
        font-family: 'Courier New', monospace;
    }
</style>
""", unsafe_allow_html=True)


class GraphAnonymizer:
    """Classe pour anonymiser des graphes sociaux - VERSION √âQUILIBR√âE"""

    def __init__(self, graph):
        self.original_graph = graph.copy()
        self.n = graph.number_of_nodes()
        self.m = graph.number_of_edges()

    def random_add_del(self, k=20):
        """Random Add/Del optimis√© pour effet visible"""
        G = self.original_graph.copy()
        added = 0
        attempts = 0
        max_attempts = k * 100

        while added < k and attempts < max_attempts:
            u, v = random.sample(list(G.nodes()), 2)
            if not G.has_edge(u, v):
                G.add_edge(u, v)
                added += 1
            attempts += 1

        edges = list(self.original_graph.edges())
        if len(edges) >= k:
            edges_to_remove = random.sample(edges, min(k, len(edges)))
            for u, v in edges_to_remove:
                if G.has_edge(u, v):
                    G.remove_edge(u, v)

        return G

    def random_switch(self, k=25):
        """Random Switch optimis√©"""
        G = self.original_graph.copy()
        successful_switches = 0

        for _ in range(k * 3):  # Plus de tentatives
            if successful_switches >= k:
                break

            edges = list(G.edges())
            if len(edges) < 2:
                break

            (u, w), (v, x) = random.sample(edges, 2)

            if u != v and u != x and w != v and w != x:
                if not G.has_edge(u, v) and not G.has_edge(w, x):
                    G.remove_edge(u, w)
                    G.remove_edge(v, x)
                    G.add_edge(u, v)
                    G.add_edge(w, x)
                    successful_switches += 1

        return G

    def k_degree_anonymity(self, k=2):
        """k-degree anonymity avec k=2 pour effet visible"""
        G = self.original_graph.copy()
        degrees = dict(G.degree())
        degree_counts = Counter(degrees.values())

        modifications = 0
        for degree, count in sorted(degree_counts.items()):
            if count < k:
                nodes_with_degree = [n for n, d in degrees.items() if d == degree]

                for node in nodes_with_degree:
                    while degrees[node] < degree + 1 and modifications < 30:
                        candidates = [n for n in G.nodes()
                                    if n != node and not G.has_edge(node, n)]
                        if candidates:
                            target = random.choice(candidates)
                            G.add_edge(node, target)
                            degrees[node] += 1
                            degrees[target] += 1
                            modifications += 1

        return G

    def generalization(self, k=4):
        """G√©n√©ralisation avec k=4 pour clusters moyens"""
        G = self.original_graph.copy()

        try:
            communities = list(nx.community.greedy_modularity_communities(G))
        except:
            # Fallback simple
            communities = [set(G.nodes())]

        super_graph = nx.Graph()
        node_to_cluster = {}
        cluster_to_nodes = {}
        cluster_id = 0

        for community in communities:
            community = set(community)

            for node in community:
                node_to_cluster[node] = cluster_id

            super_graph.add_node(cluster_id, size=len(community), nodes=list(community))
            cluster_to_nodes[cluster_id] = list(community)
            cluster_id += 1

        # Compter les ar√™tes intra et inter-clusters
        intra_edges = 0
        inter_edges = 0

        # Ajouter les super-ar√™tes
        for u, v in G.edges():
            cluster_u = node_to_cluster.get(u)
            cluster_v = node_to_cluster.get(v)

            if cluster_u is not None and cluster_v is not None:
                if cluster_u != cluster_v:
                    inter_edges += 1
                    if super_graph.has_edge(cluster_u, cluster_v):
                        super_graph[cluster_u][cluster_v]['weight'] += 1
                    else:
                        super_graph.add_edge(cluster_u, cluster_v, weight=1)
                else:
                    # Self-loops pour les ar√™tes internes
                    intra_edges += 1
                    if super_graph.has_edge(cluster_u, cluster_u):
                        super_graph[cluster_u][cluster_u]['weight'] += 1
                    else:
                        super_graph.add_edge(cluster_u, cluster_u, weight=1)

        # Stocker les statistiques
        super_graph.graph['intra_edges'] = intra_edges
        super_graph.graph['inter_edges'] = inter_edges
        super_graph.graph['cluster_to_nodes'] = cluster_to_nodes
        super_graph.graph['node_to_cluster'] = node_to_cluster

        return super_graph, node_to_cluster

    def probabilistic_obfuscation(self, k=5, epsilon=0.3):
        """(k,Œµ)-obfuscation optimis√©"""
        G = self.original_graph.copy()
        prob_graph = nx.Graph()
        prob_graph.add_nodes_from(G.nodes())

        # Ar√™tes existantes avec haute probabilit√©
        for u, v in G.edges():
            prob_graph.add_edge(u, v, probability=1.0 - epsilon/k, is_original=True)

        # Ajouter des ar√™tes potentielles
        non_edges = [(u, v) for u in G.nodes() for v in G.nodes()
                     if u < v and not G.has_edge(u, v)]

        # Ajouter ~30% des non-ar√™tes
        num_to_add = int(len(non_edges) * 0.3)
        edges_to_add = random.sample(non_edges, min(num_to_add, len(non_edges)))

        for u, v in edges_to_add:
            prob = epsilon / (2 * k)
            prob_graph.add_edge(u, v, probability=prob, is_original=False)

        return prob_graph

    def differential_privacy_edgeflip(self, epsilon=0.8):
        """EdgeFlip avec epsilon=0.8 pour effet visible"""
        G = nx.Graph()
        G.add_nodes_from(self.original_graph.nodes())

        s = 1 - np.exp(-epsilon)

        for u in self.original_graph.nodes():
            for v in self.original_graph.nodes():
                if u < v:
                    exists = self.original_graph.has_edge(u, v)

                    if random.random() < s/2:
                        if not exists:
                            G.add_edge(u, v)
                    else:
                        if exists:
                            G.add_edge(u, v)

        return G

    def differential_privacy_laplace(self, epsilon=1.2):
        """M√©canisme de Laplace optimis√©"""
        G = self.original_graph.copy()
        sensitivity = 1
        scale = sensitivity / epsilon

        new_graph = nx.Graph()
        new_graph.add_nodes_from(G.nodes())

        for u in G.nodes():
            for v in G.nodes():
                if u < v:
                    true_value = 1 if G.has_edge(u, v) else 0
                    noise = np.random.laplace(0, scale)
                    noisy_value = true_value + noise

                    if noisy_value > 0.5:
                        new_graph.add_edge(u, v)

        return new_graph


# D√©finitions des m√©thodes avec explications
METHODS = {
    "Random Add/Del": {
        "name": "Randomisation - Random Add/Del",
        "category": "1. Anonymisation par Randomisation",
        "params": {"k": 20},
        "description_short": "Ajoute k fausses ar√™tes puis supprime k vraies ar√™tes al√©atoirement",
        "description": """
### Principe en Langage Naturel

La m√©thode **Random Add/Del** est l'une des plus simples. Elle fonctionne en deux √©tapes :
1. **Ajout** : On ajoute k ar√™tes al√©atoires entre des n≈ìuds non connect√©s
2. **Suppression** : On supprime k ar√™tes existantes choisies au hasard

Cette approche cr√©e de l'incertitude en modifiant la structure du graphe de mani√®re al√©atoire.
Un attaquant qui conna√Ætrait le degr√© d'un n≈ìud ne pourra plus le retrouver avec certitude
car les degr√©s ont chang√©.

### Formalisation Math√©matique

Soit G = (V, E) le graphe original.

**Algorithme** :
```
1. Pour i = 1 √† k :
   - Choisir (u, v) ‚àà V √ó V tel que (u,v) ‚àâ E
   - E ‚Üê E ‚à™ {(u,v)}

2. Pour i = 1 √† k :
   - Choisir (u, v) ‚àà E uniform√©ment
   - E ‚Üê E \\ {(u,v)}

3. Retourner G' = (V, E)
```

**Propri√©t√©s** :
- Nombre d'ar√™tes pr√©serv√© : |E'| = |E|
- Distribution des degr√©s modifi√©e
- Pas de garantie formelle de privacy

**Complexit√©** : O(k)
        """,
        "formula": r"P(edge_{added}) = \frac{k}{|V|(|V|-1)/2 - |E|}, \quad P(edge_{removed}) = \frac{k}{|E|}",
        "privacy_level": "Faible (pas de garantie formelle)",
        "utility_preservation": "Moyenne √† Bonne"
    },

    "Random Switch": {
        "name": "Randomisation - Random Switch",
        "category": "1. Anonymisation par Randomisation",
        "params": {"k": 25},
        "description_short": "√âchange k paires d'ar√™tes en pr√©servant les degr√©s",
        "description": """
### Principe en Langage Naturel

**Random Switch** am√©liore Random Add/Del en pr√©servant une propri√©t√© importante : **les degr√©s des n≈ìuds**.

Au lieu d'ajouter/supprimer des ar√™tes ind√©pendamment, on **√©change** des ar√™tes :
- On choisit deux ar√™tes (u,w) et (v,x)
- On les remplace par (u,v) et (w,x)
- Si ces nouvelles ar√™tes n'existent pas d√©j√†

Ainsi, chaque n≈ìud conserve exactement le m√™me nombre de connexions, mais ces connexions
pointent vers d'autres n≈ìuds. C'est comme si on "r√©arrangeait" les liens sociaux sans
changer le nombre d'amis de chacun.

### Formalisation Math√©matique

**Algorithme** :
```
Pour i = 1 √† k :
  1. Choisir (u,w), (v,x) ‚àà E uniform√©ment
  2. Si u ‚â† v ‚â† w ‚â† x et (u,v) ‚àâ E et (w,x) ‚àâ E :
     - E ‚Üê E \\ {(u,w), (v,x)}
     - E ‚Üê E ‚à™ {(u,v), (w,x)}

Retourner G' = (V, E)
```

**Invariants pr√©serv√©s** :
- S√©quence de degr√©s : deg_G'(v) = deg_G(v) ‚àÄv ‚àà V
- Nombre d'ar√™tes : |E'| = |E|

**Propri√©t√© cl√©** : Les chemins et la structure globale sont modifi√©s tout en
pr√©servant les propri√©t√©s locales (degr√©s).

**Complexit√©** : O(k)
        """,
        "formula": r"deg_{G'}(v) = deg_G(v) \quad \forall v \in V",
        "privacy_level": "Faible √† Moyenne",
        "utility_preservation": "Tr√®s Bonne (degr√©s pr√©serv√©s)"
    },

    "k-degree anonymity": {
        "name": "K-Anonymisation - k-degree anonymity",
        "category": "2. K-Anonymisation",
        "params": {"k": 2},
        "description_short": "Garantit que chaque degr√© appara√Æt au moins k fois",
        "description": """
### Principe en Langage Naturel

La **k-degree anonymity** fournit une garantie formelle : chaque n≈ìud doit √™tre
**indistinguable** d'au moins k-1 autres n≈ìuds en termes de degr√©.

**Intuition** : Si un attaquant conna√Æt le degr√© d'un n≈ìud cible (ex: 5 amis),
il doit y avoir au moins k n≈ìuds avec ce m√™me degr√©. L'attaquant ne peut donc
identifier le n≈ìud cible qu'avec une probabilit√© ‚â§ 1/k.

**Exemple** : Avec k=3, si Alice a 7 amis, on s'assure qu'au moins 2 autres
personnes ont aussi 7 amis. L'attaquant ne peut pas dire laquelle est Alice.

L'algorithme ajoute des ar√™tes de mani√®re **d√©terministe** pour atteindre cette propri√©t√©.

### Formalisation Math√©matique

**D√©finition formelle** :

Un graphe G = (V, E) satisfait la k-degree anonymity si :

‚àÄd ‚àà {deg(v) : v ‚àà V}, |{v ‚àà V : deg(v) = d}| ‚â• k

C'est-√†-dire : pour tout degr√© d qui appara√Æt dans le graphe,
il doit y avoir au moins k n≈ìuds avec ce degr√©.

**Algorithme** :
```
Entr√©e : G = (V, E), k
Sortie : G' = (V, E') satisfaisant k-degree anonymity

1. Calculer la s√©quence de degr√©s D = [deg(v) : v ‚àà V]
2. Pour chaque degr√© d apparaissant moins de k fois :
   - Identifier les n≈ìuds V_d = {v : deg(v) = d}
   - Ajouter des ar√™tes pour augmenter/uniformiser les degr√©s
3. Retourner G'
```

**Garantie de privacy** :

P(identit√© de v | deg(v) = d) ‚â§ 1/k

**NP-compl√©tude** : Trouver le nombre minimum d'ar√™tes √† ajouter est NP-difficile.

**Complexit√©** : O(n¬≤) (avec heuristiques)
        """,
        "formula": r"|\{v \in V : deg(v) = d\}| \geq k \quad \forall d",
        "privacy_level": "Moyenne √† Forte (garantie k-anonymity)",
        "utility_preservation": "Bonne"
    },

    "Generalization": {
        "name": "G√©n√©ralisation - Super-nodes",
        "category": "3. Anonymisation par G√©n√©ralisation",
        "params": {"k": 4},
        "description_short": "Regroupe les n≈ìuds en super-n≈ìuds de taille ‚â• k",
        "description": """
### Principe en Langage Naturel

La **g√©n√©ralisation** adopte une approche radicalement diff√©rente : au lieu de modifier
les ar√™tes, on **regroupe** les n≈ìuds similaires en "super-n≈ìuds".

**Analogie** : C'est comme publier des statistiques par d√©partement plut√¥t que par personne.
- Au lieu de "Alice (Paris) connect√©e √† Bob (Lyon)"
- On dit "R√©gion √éle-de-France (10000 personnes) connect√©e √† R√©gion Auvergne-Rh√¥ne-Alpes (5000 personnes)"

**Avantages** :
- Protection maximale de l'identit√© individuelle
- R√©duction de la taille du graphe publi√©
- Chaque individu est "cach√©" dans un groupe de k personnes minimum

**Inconv√©nient** : Perte importante d'information structurelle fine.

### Formalisation Math√©matique

**Mod√®le de graphe g√©n√©ralis√©** :

Soit G = (V, E) le graphe original. On cr√©e une partition P = {C‚ÇÅ, C‚ÇÇ, ..., C‚Çò}
de V telle que |C·µ¢| ‚â• k ‚àÄi.

Le **super-graphe** G* = (V*, E*) est d√©fini par :
- V* = {C‚ÇÅ, C‚ÇÇ, ..., C‚Çò} (les clusters)
- E* = {(C·µ¢, C‚±º) : ‚àÉ(u,v) ‚àà E avec u ‚àà C·µ¢, v ‚àà C‚±º}

Chaque super-ar√™te (C·µ¢, C‚±º) a un **poids** :

w(C·µ¢, C‚±º) = |{(u,v) ‚àà E : u ‚àà C·µ¢, v ‚àà C‚±º}|

**Probabilit√© d'ar√™te dans le cluster** :

P(edge | C·µ¢, C‚±º) = w(C·µ¢, C‚±º) / (|C·µ¢| √ó |C‚±º|)

**Garantie de privacy** : Un individu est cach√© parmi au moins k-1 autres
dans son cluster.

**Probl√®me d'optimisation** : Trouver la partition P qui minimise la perte
d'information tout en respectant |C·µ¢| ‚â• k est NP-difficile.

**Complexit√©** : O(n¬≤) √† O(n¬≥) selon l'algorithme de clustering
        """,
        "formula": r"G^* = (V^*, E^*) \text{ o√π } V^* = \{C_i : |C_i| \geq k\}",
        "privacy_level": "Forte (k-anonymity structurelle)",
        "utility_preservation": "Faible √† Moyenne"
    },

    "Probabilistic": {
        "name": "Probabiliste - (k,Œµ)-obfuscation",
        "category": "4. Approches Probabilistes",
        "params": {"k": 5, "epsilon": 0.3},
        "description_short": "Cr√©e un graphe incertain avec probabilit√©s sur les ar√™tes",
        "description": """
### Principe en Langage Naturel

Les approches **probabilistes** cr√©ent un "graphe incertain" o√π chaque ar√™te existe
avec une certaine **probabilit√©**.

**Id√©e cl√©** : Au lieu de publier un graphe d√©terministe (ar√™te = oui/non), on publie
des probabilit√©s. Par exemple :
- Ar√™te (Alice, Bob) : 95% de probabilit√© d'exister
- Ar√™te (Alice, Charlie) : 20% de probabilit√© d'exister

Un attaquant ne peut plus √™tre certain de rien : m√™me les vraies ar√™tes ont une incertitude.

**Mod√®le (k,Œµ)-obfuscation** :
- **k** : niveau d'anonymisation souhait√© (plus k est grand, plus de protection)
- **Œµ** : param√®tre de tol√©rance (plus Œµ est petit, plus de protection)

### Formalisation Math√©matique

**Graphe incertain** :

Un graphe incertain est un triplet GÃÉ = (V, E, p) o√π :
- V : ensemble de n≈ìuds
- E : ensemble d'ar√™tes (r√©elles + potentielles)
- p : E ‚Üí [0,1] fonction de probabilit√©

**D√©finition (k,Œµ)-obfuscation** :

Pour tout n≈ìud v ‚àà V, l'entropie de Shannon de la distribution
de probabilit√© sur les k voisins candidats doit √™tre ‚â• log(k) - Œµ :

H(N_k(v)) = -‚àë·µ¢ p_i log(p_i) ‚â• log(k) - Œµ

o√π N_k(v) sont les k n≈ìuds les plus susceptibles d'√™tre voisins de v.

**Assignation des probabilit√©s** :

Pour les ar√™tes existantes :
p((u,v)) = 1 - Œµ/k

Pour les ar√™tes potentielles (ajout√©es pour l'obfuscation) :
p((u,v)) = Œµ/(2k)

**Graphe d'exemple (sample graph)** :

√Ä partir de GÃÉ, on peut g√©n√©rer des graphes compatibles en √©chantillonnant :

G_sample = (V, E_sample) o√π e ‚àà E_sample ssi X_e ‚â§ p(e), X_e ~ U[0,1]

**Propri√©t√©** : L'esp√©rance des degr√©s est pr√©serv√©e.

**Complexit√©** : O(|E| + k¬∑n)
        """,
        "formula": r"H(N_k(v)) = -\sum_i p_i \log(p_i) \geq \log(k) - \varepsilon",
        "privacy_level": "Moyenne √† Forte (contr√¥le via k et Œµ)",
        "utility_preservation": "Bonne (esp√©rance pr√©serv√©e)"
    },

    "EdgeFlip": {
        "name": "Privacy Diff√©rentielle - EdgeFlip",
        "category": "5. Privacy Diff√©rentielle",
        "params": {"epsilon": 0.8},
        "description_short": "Applique le Randomized Response Technique avec Œµ-DP",
        "description": """
### Principe en Langage Naturel

**EdgeFlip** applique le c√©l√®bre **Randomized Response Technique** (RRT) des statistiques
√† la publication de graphes.

**Intuition du RRT** (exemple classique) :
Pour une question sensible ("Avez-vous trich√© √† l'examen ?") :
- Lancez une pi√®ce en secret
- Si Face : r√©pondez la v√©rit√©
- Si Pile : r√©pondez au hasard (oui/non √† pile ou face)

R√©sultat : Votre r√©ponse a du "d√©ni plausible" mais les statistiques globales
restent calculables.

**Application √† EdgeFlip** :
Pour chaque paire de n≈ìuds (u,v) :
- Avec probabilit√© s/2 : **inverser** l'ar√™te (0‚Üí1 ou 1‚Üí0)
- Avec probabilit√© 1-s/2 : garder l'√©tat r√©el

o√π s est d√©termin√© par le param√®tre de privacy Œµ.

**Garantie Œµ-differential privacy** : La pr√©sence/absence d'une ar√™te
est prot√©g√©e avec garantie math√©matique Œµ-DP.

### Formalisation Math√©matique

**D√©finition Œµ-Differential Privacy** :

Un algorithme A satisfait Œµ-DP si pour tous graphes voisins G, G'
(diff√©rant par une ar√™te) et pour tout output O :

P[A(G) = O] ‚â§ e^Œµ ¬∑ P[A(G') = O]

Plus Œµ est petit, plus forte est la garantie de privacy.

**Algorithme EdgeFlip** :

```
Entr√©e : G = (V, E), Œµ
Param√®tre : s = 1 - e^(-Œµ)

Pour chaque paire (u, v) avec u < v :
  exists = (u,v) ‚àà E

  Avec probabilit√© s/2 :
    output = NOT exists   // Inverser
  Sinon :
    output = exists       // Garder

  Si output = TRUE :
    Ajouter (u,v) √† E_output

Retourner G_output = (V, E_output)
```

**Preuve de Œµ-DP** :

Pour une ar√™te (u,v) :

P[output=1 | exists=1] = 1 - s/2
P[output=1 | exists=0] = s/2

Ratio : (1 - s/2) / (s/2) = e^Œµ

Donc EdgeFlip satisfait Œµ-edge-DP.

**Esp√©rance du nombre d'ar√™tes** :

E[|E_output|] = |E| ¬∑ (1 - s/2) + (n(n-1)/2 - |E|) ¬∑ s/2
              ‚âà n(n-1)/4  (pour s ‚âà 1, tr√®s bruit√©)

**Complexit√©** : O(n¬≤)

**Inconv√©nient** : Complexit√© quadratique limite le passage √† l'√©chelle.
        """,
        "formula": r"P[\mathcal{A}(G) = O] \leq e^\varepsilon \cdot P[\mathcal{A}(G') = O]",
        "privacy_level": "Tr√®s Forte (Œµ-differential privacy)",
        "utility_preservation": "Variable (d√©pend de Œµ)"
    },

    "Laplace": {
        "name": "Privacy Diff√©rentielle - M√©canisme de Laplace",
        "category": "5. Privacy Diff√©rentielle",
        "params": {"epsilon": 1.2},
        "description_short": "Ajoute du bruit Laplacien pour d√©cider de l'inclusion des ar√™tes",
        "description": """
### Principe en Langage Naturel

Le **M√©canisme de Laplace** est la technique fondamentale de la privacy diff√©rentielle.

**Principe g√©n√©ral** : Pour publier une statistique f(donn√©es) de mani√®re priv√©e,
on ajoute du **bruit al√©atoire** calibr√© √† la **sensibilit√©** de f.

**Pour les graphes** :
- On consid√®re chaque ar√™te potentielle (u,v)
- Valeur r√©elle : 1 si l'ar√™te existe, 0 sinon
- On ajoute du bruit Laplacien ~ Lap(Œîf/Œµ)
- On d√©cide d'inclure l'ar√™te si valeur_bruit√©e > seuil

**Intuition du bruit** : Le bruit "masque" la contribution d'une ar√™te individuelle,
rendant impossible de d√©terminer si une ar√™te sp√©cifique √©tait pr√©sente ou non.

### Formalisation Math√©matique

**M√©canisme de Laplace g√©n√©ral** :

Pour une fonction f : D ‚Üí ‚Ñù^d, le m√©canisme de Laplace est :

M(D) = f(D) + (Y‚ÇÅ, ..., Y_d)

o√π Y_i ~ Lap(Œîf/Œµ) sont ind√©pendants et Œîf est la sensibilit√© globale.

**Sensibilit√© globale** :

Œîf = max_{G,G' voisins} ||f(G) - f(G')||‚ÇÅ

Pour les graphes (edge-DP), deux graphes sont voisins s'ils diff√®rent par une ar√™te.
Donc : Œîf = 1 pour une requ√™te de type "cette ar√™te existe-t-elle ?"

**Distribution de Laplace** :

Lap(b) a la densit√© : p(x|b) = (1/2b) ¬∑ exp(-|x|/b)
- Moyenne : 0
- Variance : 2b¬≤
- Plus b est grand, plus le bruit est important

**Application aux graphes** :

```
Entr√©e : G = (V, E), Œµ
Scale : b = 1/Œµ

Pour chaque paire (u, v) avec u < v :
  true_value = 1 si (u,v) ‚àà E, 0 sinon
  noise = Laplace(0, b)
  noisy_value = true_value + noise

  Si noisy_value > 0.5 :
    Ajouter (u,v) √† E_output

Retourner G_output = (V, E_output)
```

**Th√©or√®me** : Ce m√©canisme satisfait Œµ-differential privacy.

**Preuve (sketch)** :
Pour G et G' diff√©rant par une ar√™te (u‚ÇÄ, v‚ÇÄ) :

P[M(G) = O] / P[M(G') = O] = exp(-Œµ¬∑|f(G)-f(G')|) ‚â§ e^Œµ

car |f(G) - f(G')| ‚â§ Œîf = 1.

**Trade-off Œµ** :
- Œµ petit (ex: 0.1) : forte privacy, beaucoup de bruit, faible utilit√©
- Œµ grand (ex: 10) : faible privacy, peu de bruit, forte utilit√©
- Valeurs typiques : Œµ ‚àà [0.1, 10]

**Complexit√©** : O(n¬≤)
        """,
        "formula": r"M(D) = f(D) + \text{Lap}(\Delta f / \varepsilon)",
        "privacy_level": "Tr√®s Forte (Œµ-differential privacy)",
        "utility_preservation": "Variable (d√©pend de Œµ)"
    }
}


def calculate_anonymization_metrics(G_orig, G_anon):
    """Calcule des m√©triques d'anonymisation d√©taill√©es"""
    metrics = {}

    # Changements dans les ar√™tes
    if isinstance(G_anon, nx.Graph):
        orig_edges = set(G_orig.edges())
        anon_edges = set(G_anon.edges())

        added = len(anon_edges - orig_edges)
        removed = len(orig_edges - anon_edges)
        preserved = len(orig_edges & anon_edges)

        metrics['edges_added'] = added
        metrics['edges_removed'] = removed
        metrics['edges_preserved'] = preserved
        metrics['modification_rate'] = (added + removed) / (2 * len(orig_edges)) if len(orig_edges) > 0 else 0

        # Changements dans les degr√©s
        deg_orig = dict(G_orig.degree())
        deg_anon = dict(G_anon.degree())

        if set(deg_orig.keys()) == set(deg_anon.keys()):
            deg_changes = sum(abs(deg_orig[v] - deg_anon[v]) for v in deg_orig.keys())
            metrics['total_degree_change'] = deg_changes
            metrics['avg_degree_change'] = deg_changes / len(deg_orig)

            # Incorrectness (combien de n≈ìuds ont chang√© de degr√©)
            metrics['nodes_with_degree_change'] = sum(1 for v in deg_orig.keys() if deg_orig[v] != deg_anon[v])
            metrics['degree_preservation_rate'] = 1 - (metrics['nodes_with_degree_change'] / len(deg_orig))

        # M√©triques structurelles
        try:
            metrics['clustering_change'] = abs(
                nx.average_clustering(G_orig) - nx.average_clustering(G_anon)
            )
        except:
            metrics['clustering_change'] = None

        metrics['density_change'] = abs(nx.density(G_orig) - nx.density(G_anon))

    return metrics


def calculate_privacy_guarantees(G_orig, G_anon, method_key, method_params):
    """Calcule les garanties de privacy sp√©cifiques √† chaque m√©thode"""
    guarantees = {}

    if method_key == "k-degree anonymity":
        # V√©rifier la k-anonymit√© des degr√©s
        degrees = dict(G_anon.degree())
        degree_counts = Counter(degrees.values())

        k_value = method_params.get('k', 2)
        min_count = min(degree_counts.values()) if degree_counts else 0
        is_k_anonymous = min_count >= k_value

        guarantees['k_anonymity_satisfied'] = is_k_anonymous
        guarantees['min_degree_count'] = min_count
        guarantees['k_required'] = k_value
        guarantees['re_identification_risk'] = f"‚â§ 1/{min_count}" if min_count > 0 else "N/A"
        guarantees['unique_degrees'] = len(degree_counts)

    elif method_key == "Generalization":
        # M√©triques pour super-nodes
        if hasattr(G_anon, 'graph'):
            cluster_sizes = [G_anon.nodes[n].get('size', 0) for n in G_anon.nodes()]
            min_cluster_size = min(cluster_sizes) if cluster_sizes else 0
            max_cluster_size = max(cluster_sizes) if cluster_sizes else 0
            avg_cluster_size = np.mean(cluster_sizes) if cluster_sizes else 0

            intra_edges = G_anon.graph.get('intra_edges', 0)
            inter_edges = G_anon.graph.get('inter_edges', 0)
            total_edges = intra_edges + inter_edges

            guarantees['num_clusters'] = G_anon.number_of_nodes()
            guarantees['min_cluster_size'] = min_cluster_size
            guarantees['max_cluster_size'] = max_cluster_size
            guarantees['avg_cluster_size'] = f"{avg_cluster_size:.1f}"
            guarantees['intra_cluster_edges'] = intra_edges
            guarantees['inter_cluster_edges'] = inter_edges
            guarantees['intra_ratio'] = f"{intra_edges/total_edges*100:.1f}%" if total_edges > 0 else "N/A"
            guarantees['inter_ratio'] = f"{inter_edges/total_edges*100:.1f}%" if total_edges > 0 else "N/A"
            guarantees['re_identification_risk'] = f"‚â§ 1/{min_cluster_size}" if min_cluster_size > 0 else "N/A"
            guarantees['information_loss'] = f"{(1 - G_anon.number_of_nodes()/G_orig.number_of_nodes())*100:.1f}%"

    elif method_key in ["EdgeFlip", "Laplace"]:
        # Privacy diff√©rentielle
        epsilon = method_params.get('epsilon', 1.0)
        guarantees['epsilon'] = epsilon
        guarantees['privacy_budget'] = epsilon
        guarantees['privacy_level'] = "Forte" if epsilon < 1.0 else ("Moyenne" if epsilon < 2.0 else "Faible")
        guarantees['max_privacy_loss'] = f"e^{epsilon:.2f} ‚âà {np.exp(epsilon):.2f}"

        # Calculer le taux de faux positifs/n√©gatifs attendu
        if method_key == "EdgeFlip":
            s = 1 - np.exp(-epsilon)
            false_positive_rate = s/2
            false_negative_rate = s/2
            guarantees['expected_false_positive_rate'] = f"{false_positive_rate*100:.1f}%"
            guarantees['expected_false_negative_rate'] = f"{false_negative_rate*100:.1f}%"

    elif method_key == "Probabilistic":
        # (k,Œµ)-obfuscation
        k = method_params.get('k', 5)
        eps = method_params.get('epsilon', 0.3)

        guarantees['k_neighborhood'] = k
        guarantees['epsilon_tolerance'] = eps
        guarantees['min_entropy'] = f"log({k}) - {eps:.2f} ‚âà {np.log(k) - eps:.2f}"
        guarantees['uncertainty_level'] = "√âlev√©e" if eps < 0.5 else "Moyenne"

    elif method_key == "Random Switch":
        # Pr√©servation de la s√©quence de degr√©s
        deg_orig = sorted([d for n, d in G_orig.degree()])
        deg_anon = sorted([d for n, d in G_anon.degree()])

        degree_sequence_preserved = deg_orig == deg_anon
        guarantees['degree_sequence_preserved'] = degree_sequence_preserved
        guarantees['structural_property'] = "S√©quence de degr√©s pr√©serv√©e" if degree_sequence_preserved else "Modifi√©e"

    elif method_key == "Random Add/Del":
        # Quantifier l'incertitude introduite
        k = method_params.get('k', 20)
        total_possible_edges = G_orig.number_of_nodes() * (G_orig.number_of_nodes() - 1) // 2

        guarantees['edges_modified'] = 2 * k  # k ajout√©es + k supprim√©es (th√©orique)
        guarantees['modification_budget'] = k
        guarantees['structural_uncertainty'] = "Mod√©r√©e"

    return guarantees


def plot_graph_comparison(G_orig, G_anon, method_name, node_to_cluster=None):
    """Cr√©e une comparaison visuelle des graphes"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))

    # Position commune pour comparaison
    pos = nx.spring_layout(G_orig, seed=42, k=0.5, iterations=50)

    # Graphe original
    if node_to_cluster is not None:
        # Si c'est une g√©n√©ralisation, colorier par cluster
        clusters = {}
        for node, cluster in node_to_cluster.items():
            if cluster not in clusters:
                clusters[cluster] = []
            clusters[cluster].append(node)

        # G√©n√©rer des couleurs pour chaque cluster
        import matplotlib.cm as cm
        colors = cm.tab20(np.linspace(0, 1, len(clusters)))

        # Dessiner les n≈ìuds par cluster
        for idx, (cluster_id, nodes) in enumerate(clusters.items()):
            node_color = colors[idx % len(colors)]
            nx.draw_networkx_nodes(G_orig, pos, nodelist=nodes, ax=ax1,
                                  node_color=[node_color], node_size=500, alpha=0.7)

            # Encercler le cluster
            node_positions = np.array([pos[n] for n in nodes])
            if len(node_positions) > 0:
                center = node_positions.mean(axis=0)
                max_dist = np.max(np.linalg.norm(node_positions - center, axis=1))
                circle = plt.Circle(center, max_dist + 0.15, color=node_color,
                                  fill=False, linewidth=2.5, linestyle='--', alpha=0.6)
                ax1.add_patch(circle)

        # Dessiner les ar√™tes par type
        intra_edges = []
        inter_edges = []
        for u, v in G_orig.edges():
            if node_to_cluster[u] == node_to_cluster[v]:
                intra_edges.append((u, v))
            else:
                inter_edges.append((u, v))

        if intra_edges:
            nx.draw_networkx_edges(G_orig, pos, intra_edges, ax=ax1,
                                  edge_color='green', width=2, alpha=0.4,
                                  label='Intra-cluster')
        if inter_edges:
            nx.draw_networkx_edges(G_orig, pos, inter_edges, ax=ax1,
                                  edge_color='red', width=1.5, alpha=0.5,
                                  label='Inter-cluster', style='dashed')

        ax1.legend(loc='upper right')
        ax1.set_title(f'Graphe Original avec Clusters\n{G_orig.number_of_nodes()} n≈ìuds, {len(clusters)} clusters',
                      fontsize=14, fontweight='bold')
    else:
        # Affichage normal
        nx.draw_networkx_nodes(G_orig, pos, ax=ax1, node_color='lightblue',
                              node_size=500, alpha=0.9)
        nx.draw_networkx_edges(G_orig, pos, ax=ax1, edge_color='gray',
                              width=1.5, alpha=0.6)
        ax1.set_title(f'Graphe Original\n{G_orig.number_of_nodes()} n≈ìuds, {G_orig.number_of_edges()} ar√™tes',
                      fontsize=14, fontweight='bold')

    nx.draw_networkx_labels(G_orig, pos, ax=ax1, font_size=8, font_weight='bold')
    ax1.axis('off')

    # Graphe anonymis√©
    if isinstance(G_anon, nx.Graph) and G_anon.number_of_nodes() > 0:
        # Adapter la position si diff√©rent nombre de n≈ìuds
        if set(G_anon.nodes()) != set(G_orig.nodes()):
            pos_anon = nx.spring_layout(G_anon, seed=42, k=0.5, iterations=50)

            # Si c'est un super-graphe, ajuster la visualisation
            if node_to_cluster is not None and hasattr(G_anon, 'graph'):
                # Dessiner le super-graphe
                node_sizes = [G_anon.nodes[n].get('size', 1) * 300 for n in G_anon.nodes()]
                nx.draw_networkx_nodes(G_anon, pos_anon, ax=ax2, node_color='orange',
                                      node_size=node_sizes, alpha=0.8)

                # Dessiner les ar√™tes avec poids
                edges = G_anon.edges()
                weights = [G_anon[u][v].get('weight', 1) for u, v in edges]
                max_weight = max(weights) if weights else 1

                for (u, v), weight in zip(edges, weights):
                    if u == v:  # Self-loop (ar√™tes intra-cluster)
                        # Dessiner une boucle
                        continue
                    else:
                        width = 1 + 4 * (weight / max_weight)
                        nx.draw_networkx_edges(G_anon, pos_anon, [(u, v)], ax=ax2,
                                              width=width, alpha=0.6, edge_color='purple')

                # Labels avec taille de cluster
                labels = {n: f"C{n}\n({G_anon.nodes[n].get('size', '?')})" for n in G_anon.nodes()}
                nx.draw_networkx_labels(G_anon, pos_anon, labels, ax=ax2,
                                       font_size=10, font_weight='bold')

                ax2.set_title(f'Super-Graphe - {method_name}\n{G_anon.number_of_nodes()} super-n≈ìuds',
                             fontsize=14, fontweight='bold')
            else:
                # Graphe normal avec n≈ìuds diff√©rents
                nx.draw_networkx_nodes(G_anon, pos_anon, ax=ax2, node_color='lightgreen',
                                      node_size=500, alpha=0.9)
                nx.draw_networkx_edges(G_anon, pos_anon, ax=ax2, edge_color='gray',
                                      width=1.5, alpha=0.6)
                nx.draw_networkx_labels(G_anon, pos_anon, ax=ax2, font_size=8, font_weight='bold')
                ax2.set_title(f'Graphe Anonymis√© - {method_name}\n{G_anon.number_of_nodes()} n≈ìuds',
                             fontsize=14, fontweight='bold')
        else:
            pos_anon = pos

            # Colorer les ar√™tes diff√©remment
            orig_edges = set(G_orig.edges())

            # Dessiner les n≈ìuds
            nx.draw_networkx_nodes(G_anon, pos_anon, ax=ax2, node_color='lightgreen',
                                  node_size=500, alpha=0.9)

            # Dessiner les ar√™tes par type
            preserved_edges = [(u,v) for u,v in G_anon.edges()
                              if (u,v) in orig_edges or (v,u) in orig_edges]
            added_edges = [(u,v) for u,v in G_anon.edges()
                          if (u,v) not in orig_edges and (v,u) not in orig_edges]

            if preserved_edges:
                nx.draw_networkx_edges(G_anon, pos_anon, preserved_edges, ax=ax2,
                                      edge_color='blue', width=1.5, alpha=0.6,
                                      style='solid', label='Ar√™tes pr√©serv√©es')
            if added_edges:
                nx.draw_networkx_edges(G_anon, pos_anon, added_edges, ax=ax2,
                                      edge_color='red', width=1.5, alpha=0.6,
                                      style='dashed', label='Ar√™tes ajout√©es')

            nx.draw_networkx_labels(G_anon, pos_anon, ax=ax2, font_size=8, font_weight='bold')
            ax2.legend(loc='upper right')

            ax2.set_title(f'Graphe Anonymis√© - {method_name}\n{G_anon.number_of_nodes()} n≈ìuds, {G_anon.number_of_edges()} ar√™tes',
                         fontsize=14, fontweight='bold')
    else:
        ax2.text(0.5, 0.5, 'Graphe non visualisable\n(format incompatible)',
                ha='center', va='center', fontsize=12)
        ax2.set_title(f'Graphe Anonymis√© - {method_name}', fontsize=14, fontweight='bold')

    ax2.axis('off')

    plt.tight_layout()
    return fig


def plot_degree_distribution(G_orig, G_anon, method_name):
    """Compare les distributions de degr√©s"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    # Distribution originale
    degrees_orig = [d for n, d in G_orig.degree()]
    ax1.hist(degrees_orig, bins=range(max(degrees_orig)+2),
            alpha=0.7, color='blue', edgecolor='black', rwidth=0.8)
    ax1.set_xlabel('Degr√©', fontsize=12)
    ax1.set_ylabel('Nombre de n≈ìuds', fontsize=12)
    ax1.set_title('Distribution des degr√©s - Original', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3, linestyle='--')
    ax1.set_axisbelow(True)

    # Distribution anonymis√©e
    if isinstance(G_anon, nx.Graph) and G_anon.number_of_nodes() > 0:
        if set(G_anon.nodes()).issubset(set(G_orig.nodes())):
            degrees_anon = [d for n, d in G_anon.degree()]
            ax2.hist(degrees_anon, bins=range(max(degrees_anon)+2),
                    alpha=0.7, color='green', edgecolor='black', rwidth=0.8)
            ax2.set_xlabel('Degr√©', fontsize=12)
            ax2.set_ylabel('Nombre de n≈ìuds', fontsize=12)
            ax2.set_title(f'Distribution des degr√©s - {method_name}', fontsize=14, fontweight='bold')
            ax2.grid(True, alpha=0.3, linestyle='--')
            ax2.set_axisbelow(True)
        else:
            ax2.text(0.5, 0.5, 'Distribution non comparable\n(n≈ìuds diff√©rents)',
                    ha='center', va='center', fontsize=12)
            ax2.axis('off')
    else:
        ax2.text(0.5, 0.5, 'Pas de distribution\n(format non standard)',
                ha='center', va='center', fontsize=12)
        ax2.axis('off')

    plt.tight_layout()
    return fig


def simulate_degree_attack(G_orig, G_anon, target_node=0):
    """Simule une attaque par degr√© sur le graphe"""
    results = {
        'attack_type': 'Degree Attack',
        'target_node': target_node,
        'success': False,
        'candidates': [],
        'explanation': ''
    }

    if not isinstance(G_anon, nx.Graph):
        results['explanation'] = "Attaque impossible sur ce type de graphe (super-nodes)"
        return results

    # Degr√© du n≈ìud cible dans le graphe original
    target_degree = G_orig.degree(target_node)

    # Chercher les n≈ìuds ayant ce degr√© dans le graphe anonymis√©
    candidates = [n for n in G_anon.nodes() if G_anon.degree(n) == target_degree]

    results['candidates'] = candidates
    results['target_degree'] = target_degree

    if len(candidates) == 1:
        results['success'] = True
        results['re_identified_node'] = candidates[0]
        results['explanation'] = f"‚úÖ R√©-identification r√©ussie ! Le n≈ìud {target_node} a un degr√© unique ({target_degree}). Un seul n≈ìud candidat trouv√©."
    elif len(candidates) == 0:
        results['success'] = False
        results['explanation'] = f"‚ùå Aucun n≈ìud avec degr√© {target_degree} trouv√© (le degr√© a √©t√© modifi√©)."
    else:
        results['success'] = False
        results['explanation'] = f"‚ö†Ô∏è R√©-identification ambigu√´ : {len(candidates)} n≈ìuds ont le degr√© {target_degree}. Probabilit√© de succ√®s : {1/len(candidates)*100:.1f}%"

    return results


def simulate_subgraph_attack(G_orig, G_anon, target_node=0):
    """Simule une attaque par sous-graphe (recherche de triangles)"""
    results = {
        'attack_type': 'Subgraph Attack',
        'target_node': target_node,
        'success': False,
        'candidates': [],
        'explanation': ''
    }

    if not isinstance(G_anon, nx.Graph):
        results['explanation'] = "Attaque impossible sur ce type de graphe (super-nodes)"
        return results

    # Trouver les triangles contenant le n≈ìud cible dans le graphe original
    target_triangles = []
    for u, v in G_orig.edges(target_node):
        if G_orig.has_edge(u, v):
            target_triangles.append(sorted([target_node, u, v]))

    if not target_triangles:
        results['explanation'] = f"Le n≈ìud {target_node} ne fait partie d'aucun triangle."
        return results

    # Caract√©ristiques du n≈ìud : degr√© + nombre de triangles
    target_degree = G_orig.degree(target_node)
    target_triangle_count = len(target_triangles)

    # Chercher les n≈ìuds avec des caract√©ristiques similaires
    candidates = []
    for n in G_anon.nodes():
        if G_anon.degree(n) == target_degree:
            # Compter les triangles pour ce n≈ìud
            node_triangles = 0
            for u, v in G_anon.edges(n):
                if G_anon.has_edge(u, v):
                    node_triangles += 1

            if node_triangles == target_triangle_count:
                candidates.append(n)

    results['candidates'] = candidates
    results['target_degree'] = target_degree
    results['target_triangles'] = target_triangle_count

    if len(candidates) == 1:
        results['success'] = True
        results['re_identified_node'] = candidates[0]
        results['explanation'] = f"‚úÖ R√©-identification r√©ussie ! Pattern unique : degr√© {target_degree}, {target_triangle_count} triangles."
    elif len(candidates) == 0:
        results['success'] = False
        results['explanation'] = f"‚ùå Aucun n≈ìud correspondant (structure modifi√©e)."
    else:
        results['success'] = False
        results['explanation'] = f"‚ö†Ô∏è {len(candidates)} candidats avec pattern similaire. Probabilit√© : {1/len(candidates)*100:.1f}%"

    return results


def calculate_utility_metrics(G_orig, G_anon):
    """Calcule les m√©triques d'utilit√© du graphe"""
    metrics = {}

    if not isinstance(G_anon, nx.Graph):
        return {'type': 'super-graph', 'comparable': False}

    # M√©triques de base
    metrics['num_nodes'] = G_anon.number_of_nodes()
    metrics['num_edges'] = G_anon.number_of_edges()
    metrics['density'] = nx.density(G_anon)

    # Clustering
    try:
        metrics['avg_clustering'] = nx.average_clustering(G_anon)
    except:
        metrics['avg_clustering'] = None

    # Centralit√© moyenne
    try:
        degree_centrality = nx.degree_centrality(G_anon)
        metrics['avg_degree_centrality'] = np.mean(list(degree_centrality.values()))
    except:
        metrics['avg_degree_centrality'] = None

    # Diam√®tre (si graphe connexe)
    try:
        if nx.is_connected(G_anon):
            metrics['diameter'] = nx.diameter(G_anon)
            metrics['avg_shortest_path'] = nx.average_shortest_path_length(G_anon)
        else:
            # Prendre la plus grande composante connexe
            largest_cc = max(nx.connected_components(G_anon), key=len)
            subgraph = G_anon.subgraph(largest_cc)
            metrics['diameter'] = nx.diameter(subgraph)
            metrics['avg_shortest_path'] = nx.average_shortest_path_length(subgraph)
    except:
        metrics['diameter'] = None
        metrics['avg_shortest_path'] = None

    # Pr√©servation de la distribution des degr√©s
    orig_degrees = sorted([d for n, d in G_orig.degree()])
    anon_degrees = sorted([d for n, d in G_anon.degree()])

    if len(orig_degrees) == len(anon_degrees):
        # Corr√©lation de Spearman
        from scipy.stats import spearmanr
        try:
            corr, _ = spearmanr(orig_degrees, anon_degrees)
            metrics['degree_correlation'] = corr
        except:
            metrics['degree_correlation'] = None

    return metrics


def calculate_privacy_metrics_separated(G_orig, G_anon, method_key, method_params):
    """Calcule les m√©triques de privacy s√©par√©es"""
    metrics = {}

    if method_key == "k-degree anonymity":
        degrees = dict(G_anon.degree()) if isinstance(G_anon, nx.Graph) else {}
        degree_counts = Counter(degrees.values()) if degrees else Counter()
        k_value = method_params.get('k', 2)
        min_count = min(degree_counts.values()) if degree_counts else 0

        metrics['k_value'] = k_value
        metrics['min_anonymity_set'] = min_count
        metrics['satisfies_k_anonymity'] = min_count >= k_value
        metrics['re_identification_probability'] = 1/min_count if min_count > 0 else 1.0

    elif method_key in ["EdgeFlip", "Laplace"]:
        epsilon = method_params.get('epsilon', 1.0)
        metrics['epsilon_budget'] = epsilon
        metrics['privacy_loss_bound'] = np.exp(epsilon)
        metrics['privacy_level'] = "Forte (Œµ<1)" if epsilon < 1.0 else ("Moyenne (1‚â§Œµ<2)" if epsilon < 2.0 else "Faible (Œµ‚â•2)")

        if method_key == "EdgeFlip":
            s = 1 - np.exp(-epsilon)
            metrics['flip_probability'] = s
            metrics['expected_noise_edges'] = int(G_orig.number_of_edges() * s / 2)

    elif method_key == "Probabilistic":
        k = method_params.get('k', 5)
        eps = method_params.get('epsilon', 0.3)
        metrics['k_candidates'] = k
        metrics['epsilon_tolerance'] = eps
        metrics['min_entropy'] = np.log(k) - eps
        metrics['confusion_factor'] = k

    elif method_key == "Generalization":
        if hasattr(G_anon, 'graph') and 'cluster_to_nodes' in G_anon.graph:
            cluster_sizes = [len(nodes) for nodes in G_anon.graph['cluster_to_nodes'].values()]
            metrics['min_cluster_size'] = min(cluster_sizes) if cluster_sizes else 0
            metrics['avg_cluster_size'] = np.mean(cluster_sizes) if cluster_sizes else 0
            metrics['max_privacy'] = 1/min(cluster_sizes) if cluster_sizes else 1.0

    return metrics


def main():
    """Application principale Streamlit"""

    # En-t√™te
    st.markdown('<p class="main-header">üîí Anonymisation de Graphes Sociaux</p>',
                unsafe_allow_html=True)
    st.markdown("---")

    st.markdown("""
    ### Application Interactive bas√©e sur la th√®se de NGUYEN Huu-Hiep (2016)

    Cette application d√©montre les **5 types de m√©thodes d'anonymisation** de graphes sociaux
    avec explications math√©matiques d√©taill√©es et m√©triques d'anonymisation.
    """)

    # Sidebar - S√©lection de la m√©thode
    st.sidebar.title("‚öôÔ∏è Configuration")

    st.sidebar.markdown("### üìä Graphe de Test")
    graph_choice = st.sidebar.selectbox(
        "Choisir un graphe",
        ["Karate Club (34 n≈ìuds)", "Graphe Al√©atoire Petit (20 n≈ìuds)",
         "Graphe Al√©atoire Moyen (50 n≈ìuds)"]
    )

    # Charger le graphe
    if "Karate" in graph_choice:
        G = nx.karate_club_graph()
        st.sidebar.success(f"‚úì Graphe Karate Club charg√©: {G.number_of_nodes()} n≈ìuds, {G.number_of_edges()} ar√™tes")
    elif "Petit" in graph_choice:
        G = nx.erdos_renyi_graph(20, 0.15, seed=42)
        st.sidebar.success(f"‚úì Graphe al√©atoire charg√©: {G.number_of_nodes()} n≈ìuds, {G.number_of_edges()} ar√™tes")
    else:
        G = nx.erdos_renyi_graph(50, 0.1, seed=42)
        st.sidebar.success(f"‚úì Graphe al√©atoire charg√©: {G.number_of_nodes()} n≈ìuds, {G.number_of_edges()} ar√™tes")

    st.sidebar.markdown("---")
    st.sidebar.markdown("### üî¨ M√©thode d'Anonymisation")

    method_key = st.sidebar.selectbox(
        "Choisir une m√©thode",
        list(METHODS.keys()),
        format_func=lambda x: METHODS[x]["name"]
    )

    method = METHODS[method_key]

    st.sidebar.markdown(f"**Cat√©gorie** : {method['category']}")
    st.sidebar.markdown(f"**Description** : {method['description_short']}")

    # Section de param√®tres modulables
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ‚öôÔ∏è Budget de Privacy (Modulable)")

    # Param√®tres dynamiques selon la m√©thode
    dynamic_params = {}

    if method_key in ["Random Add/Del", "Random Switch"]:
        k_value = st.sidebar.slider(
            "k = Nombre de modifications",
            min_value=5,
            max_value=50,
            value=method['params']['k'],
            step=5,
            help="Nombre d'ar√™tes √† modifier (ajout/suppression ou √©change)"
        )
        dynamic_params['k'] = k_value

    elif method_key == "k-degree anonymity":
        k_value = st.sidebar.slider(
            "k = Taille minimale des groupes",
            min_value=2,
            max_value=10,
            value=method['params']['k'],
            step=1,
            help="Nombre minimum de n≈ìuds ayant le m√™me degr√©"
        )
        dynamic_params['k'] = k_value

    elif method_key == "Generalization":
        k_value = st.sidebar.slider(
            "k = Taille minimale des clusters",
            min_value=2,
            max_value=10,
            value=method['params']['k'],
            step=1,
            help="Nombre minimum de n≈ìuds dans chaque cluster"
        )
        dynamic_params['k'] = k_value

    elif method_key == "Probabilistic":
        k_value = st.sidebar.slider(
            "k = Nombre de graphes candidats",
            min_value=3,
            max_value=15,
            value=method['params']['k'],
            step=1,
            help="Nombre minimum de graphes plausibles"
        )
        epsilon_value = st.sidebar.slider(
            "Œµ = Marge d'entropie",
            min_value=0.1,
            max_value=1.0,
            value=method['params']['epsilon'],
            step=0.1,
            help="Tol√©rance dans l'incertitude (plus petit = plus de privacy)"
        )
        dynamic_params['k'] = k_value
        dynamic_params['epsilon'] = epsilon_value

    elif method_key in ["EdgeFlip", "Laplace"]:
        epsilon_value = st.sidebar.slider(
            "Œµ = Budget de Privacy",
            min_value=0.1,
            max_value=3.0,
            value=method['params']['epsilon'],
            step=0.1,
            help="Budget de privacy diff√©rentielle (plus petit = plus de privacy, moins d'utilit√©)"
        )
        dynamic_params['epsilon'] = epsilon_value

        # Afficher l'impact du budget
        privacy_loss = np.exp(epsilon_value)
        if epsilon_value < 1.0:
            st.sidebar.success(f"‚úÖ Privacy Forte (perte ‚â§ {privacy_loss:.2f}x)")
        elif epsilon_value < 2.0:
            st.sidebar.warning(f"‚ö†Ô∏è Privacy Moyenne (perte ‚â§ {privacy_loss:.2f}x)")
        else:
            st.sidebar.error(f"‚ùå Privacy Faible (perte ‚â§ {privacy_loss:.2f}x)")

    # Bouton pour anonymiser
    st.sidebar.markdown("---")
    if st.sidebar.button("üöÄ Anonymiser le Graphe", type="primary"):
        st.session_state.anonymized = True
        st.session_state.method_key = method_key
        st.session_state.method_params = dynamic_params  # Sauvegarder les param√®tres utilis√©s

        # Anonymiser
        anonymizer = GraphAnonymizer(G)

        with st.spinner('Anonymisation en cours...'):
            node_to_cluster = None
            if method_key == "Random Add/Del":
                G_anon = anonymizer.random_add_del(**dynamic_params)
            elif method_key == "Random Switch":
                G_anon = anonymizer.random_switch(**dynamic_params)
            elif method_key == "k-degree anonymity":
                G_anon = anonymizer.k_degree_anonymity(**dynamic_params)
            elif method_key == "Generalization":
                G_anon, node_to_cluster = anonymizer.generalization(**dynamic_params)
                st.session_state.node_to_cluster = node_to_cluster
            elif method_key == "Probabilistic":
                G_anon = anonymizer.probabilistic_obfuscation(**dynamic_params)
            elif method_key == "EdgeFlip":
                G_anon = anonymizer.differential_privacy_edgeflip(**dynamic_params)
            elif method_key == "Laplace":
                G_anon = anonymizer.differential_privacy_laplace(**dynamic_params)

            st.session_state.G_anon = G_anon
            st.session_state.G_orig = G
            if node_to_cluster is None:
                st.session_state.node_to_cluster = None

    # Affichage des r√©sultats
    if 'anonymized' in st.session_state and st.session_state.anonymized:
        G_orig = st.session_state.G_orig
        G_anon = st.session_state.G_anon
        current_method = METHODS[st.session_state.method_key]

        # Onglets - VERSION AM√âLIOR√âE avec 8 onglets
        tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
            "üìä R√©sultats",
            "üìñ D√©finitions",
            "üìà M√©triques Utilit√©",
            "üîí M√©triques Privacy",
            "üéØ Simulations d'Attaques",
            "üõ°Ô∏è Attaques & Garanties",
            "üìö Dict. Attaques",
            "üîç Dict. Propri√©t√©s"
        ])

        with tab1:
            st.markdown("## üìä R√©sultats de l'Anonymisation")

            col1, col2 = st.columns(2)

            with col1:
                st.metric("N≈ìuds Originaux", G_orig.number_of_nodes())
                st.metric("Ar√™tes Originales", G_orig.number_of_edges())

            with col2:
                if isinstance(G_anon, nx.Graph):
                    st.metric("N≈ìuds Anonymis√©s", G_anon.number_of_nodes())
                    st.metric("Ar√™tes Anonymis√©es", G_anon.number_of_edges(),
                             delta=f"{G_anon.number_of_edges() - G_orig.number_of_edges():+d}")
                else:
                    st.info("Format de graphe non standard (super-nodes)")

            st.markdown("---")
            st.markdown("### Comparaison Visuelle")

            node_to_cluster = st.session_state.get('node_to_cluster', None)
            fig = plot_graph_comparison(G_orig, G_anon, current_method['name'], node_to_cluster)
            st.pyplot(fig)

            # Afficher les statistiques sp√©cifiques aux super-nodes
            if st.session_state.method_key == "Generalization" and hasattr(G_anon, 'graph'):
                st.markdown("---")
                st.markdown("### üìä Statistiques des Super-Nodes")

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Ar√™tes Intra-Cluster", G_anon.graph.get('intra_edges', 'N/A'),
                             help="Ar√™tes √† l'int√©rieur des clusters (vert)")
                with col2:
                    st.metric("Ar√™tes Inter-Cluster", G_anon.graph.get('inter_edges', 'N/A'),
                             help="Ar√™tes entre diff√©rents clusters (rouge)")
                with col3:
                    total = G_anon.graph.get('intra_edges', 0) + G_anon.graph.get('inter_edges', 0)
                    ratio = G_anon.graph.get('intra_edges', 0) / total * 100 if total > 0 else 0
                    st.metric("Ratio Intra/Total", f"{ratio:.1f}%")

            st.markdown("---")
            st.markdown("### Distribution des Degr√©s")

            fig_dist = plot_degree_distribution(G_orig, G_anon, current_method['name'])
            st.pyplot(fig_dist)

        with tab2:
            st.markdown("## üìñ D√©finitions des Concepts d'Anonymisation")

            st.markdown("""
            Cette section pr√©sente les d√©finitions formelles et intuitions pour chaque type d'anonymisation.
            Choisissez un concept ci-dessous pour voir sa d√©finition compl√®te.
            """)

            st.markdown("---")

            # S√©lecteur de concept
            concept_keys = list(ANONYMIZATION_DEFINITIONS.keys())
            concept_names = [ANONYMIZATION_DEFINITIONS[k]['name'] for k in concept_keys]

            selected_concept_name = st.selectbox(
                "Choisir un concept √† explorer",
                concept_names
            )

            # Trouver la cl√© correspondante
            selected_concept_key = concept_keys[concept_names.index(selected_concept_name)]
            concept = ANONYMIZATION_DEFINITIONS[selected_concept_key]

            st.markdown(f"### {concept['name']}")

            with st.expander("üìù D√©finition Formelle", expanded=True):
                st.markdown(concept['definition'])
                st.markdown("**Formule math√©matique** :")
                st.code(concept['math_formula'], language="text")

            with st.expander("üí° Intuition (Explication en langage naturel)", expanded=True):
                st.markdown(concept['intuition'])

            with st.expander("üîí Garantie de Privacy"):
                st.info(f"**Garantie** : {concept['privacy_guarantee']}")

            with st.expander("‚öôÔ∏è Signification des Param√®tres"):
                st.markdown(concept['parameter_meaning'])

            st.markdown("---")
            st.markdown(f"### üî¨ M√©thode Actuelle : {current_method['name']}")

            with st.expander("üìö Explication de la m√©thode actuelle"):
                st.markdown(current_method['description'])
                st.markdown("**Formule** :")
                st.latex(current_method['formula'])

                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**üîí Niveau de Privacy**")
                    st.info(current_method['privacy_level'])
                with col2:
                    st.markdown("**üìä Pr√©servation de l'Utilit√©**")
                    st.info(current_method['utility_preservation'])

        with tab3:
            st.markdown("## üìà M√©triques d'Utilit√© du Graphe")

            st.markdown("""
            Ces m√©triques mesurent la **pr√©servation de l'utilit√©** du graphe apr√®s anonymisation.
            Plus ces m√©triques sont proches du graphe original, mieux l'utilit√© est pr√©serv√©e.
            """)

            utility_metrics = calculate_utility_metrics(G_orig, G_anon)

            if utility_metrics.get('comparable', True):
                st.markdown("### üìä M√©triques de Base")

                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    st.metric("N≈ìuds", utility_metrics.get('num_nodes', 'N/A'))
                with col2:
                    st.metric("Ar√™tes", utility_metrics.get('num_edges', 'N/A'))
                with col3:
                    orig_density = nx.density(G_orig)
                    anon_density = utility_metrics.get('density', 0)
                    delta_density = anon_density - orig_density
                    st.metric("Densit√©", f"{anon_density:.3f}", delta=f"{delta_density:+.3f}")
                with col4:
                    if utility_metrics.get('avg_clustering') is not None:
                        orig_clust = nx.average_clustering(G_orig)
                        anon_clust = utility_metrics['avg_clustering']
                        delta_clust = anon_clust - orig_clust
                        st.metric("Clustering Moyen", f"{anon_clust:.3f}", delta=f"{delta_clust:+.3f}")

                st.markdown("---")
                st.markdown("### üåê M√©triques Globales")

                col1, col2, col3 = st.columns(3)

                with col1:
                    if utility_metrics.get('diameter') is not None:
                        try:
                            if nx.is_connected(G_orig):
                                orig_diam = nx.diameter(G_orig)
                            else:
                                largest_cc = max(nx.connected_components(G_orig), key=len)
                                orig_diam = nx.diameter(G_orig.subgraph(largest_cc))
                            delta_diam = utility_metrics['diameter'] - orig_diam
                            st.metric("Diam√®tre", utility_metrics['diameter'], delta=f"{delta_diam:+d}")
                        except:
                            st.metric("Diam√®tre", utility_metrics['diameter'])

                with col2:
                    if utility_metrics.get('avg_shortest_path') is not None:
                        try:
                            if nx.is_connected(G_orig):
                                orig_asp = nx.average_shortest_path_length(G_orig)
                            else:
                                largest_cc = max(nx.connected_components(G_orig), key=len)
                                orig_asp = nx.average_shortest_path_length(G_orig.subgraph(largest_cc))
                            delta_asp = utility_metrics['avg_shortest_path'] - orig_asp
                            st.metric("Chemin Moyen", f"{utility_metrics['avg_shortest_path']:.2f}", delta=f"{delta_asp:+.2f}")
                        except:
                            st.metric("Chemin Moyen", f"{utility_metrics['avg_shortest_path']:.2f}")

                with col3:
                    if utility_metrics.get('degree_correlation') is not None:
                        st.metric("Corr√©lation des Degr√©s", f"{utility_metrics['degree_correlation']:.3f}",
                                 help="Coefficient de Spearman : 1 = parfait, 0 = aucune corr√©lation")

                st.markdown("---")
                st.markdown("### üìâ Trade-off Utilit√© vs Modifications")

                metrics = calculate_anonymization_metrics(G_orig, G_anon)

                if metrics:
                    col1, col2 = st.columns(2)

                    with col1:
                        st.markdown("**Modifications des Ar√™tes**")
                        added = metrics.get('edges_added', 0)
                        removed = metrics.get('edges_removed', 0)
                        preserved = metrics.get('edges_preserved', 0)

                        df_edges = pd.DataFrame({
                            'Type': ['Pr√©serv√©es', 'Ajout√©es', 'Supprim√©es'],
                            'Nombre': [preserved, added, removed]
                        })
                        st.bar_chart(df_edges.set_index('Type'))

                    with col2:
                        st.markdown("**Taux de Modification**")
                        rate = metrics.get('modification_rate', 0)
                        st.progress(min(rate, 1.0))
                        st.metric("Taux de modification", f"{rate*100:.1f}%")

                        if rate < 0.1:
                            st.success("‚úÖ Utilit√© tr√®s bien pr√©serv√©e")
                        elif rate < 0.3:
                            st.info("‚ÑπÔ∏è Utilit√© correctement pr√©serv√©e")
                        else:
                            st.warning("‚ö†Ô∏è Modifications importantes")

            else:
                st.info("Graphe de type super-nodes : m√©triques d'utilit√© non directement comparables")

        with tab4:
            st.markdown("## üîí M√©triques de Privacy")

            st.markdown("""
            Ces m√©triques quantifient la **protection de la vie priv√©e** offerte par l'anonymisation.
            Plus ces valeurs sont √©lev√©es, meilleure est la protection.
            """)

            method_params = st.session_state.get('method_params', {})
            privacy_metrics = calculate_privacy_metrics_separated(G_orig, G_anon, st.session_state.method_key, method_params)

            if privacy_metrics:
                st.markdown("### üõ°Ô∏è Garanties de Privacy")

                if 'k_value' in privacy_metrics:
                    # k-anonymity
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.metric("k requis", privacy_metrics['k_value'])
                    with col2:
                        st.metric("Ensemble d'anonymat min.", privacy_metrics['min_anonymity_set'])
                    with col3:
                        satisfies = privacy_metrics['satisfies_k_anonymity']
                        if satisfies:
                            st.success(f"‚úÖ {privacy_metrics['k_value']}-anonymit√© satisfaite")
                        else:
                            st.error(f"‚ùå {privacy_metrics['k_value']}-anonymit√© NON satisfaite")

                    st.markdown("---")
                    prob = privacy_metrics['re_identification_probability']
                    st.markdown(f"**Probabilit√© de r√©-identification** : {prob:.3f} ({prob*100:.1f}%)")

                    st.progress(1 - prob)

                    if prob < 0.2:
                        st.success("‚úÖ Risque de r√©-identification faible")
                    elif prob < 0.5:
                        st.warning("‚ö†Ô∏è Risque de r√©-identification mod√©r√©")
                    else:
                        st.error("‚ùå Risque de r√©-identification √©lev√©")

                elif 'epsilon_budget' in privacy_metrics:
                    # Differential Privacy
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        eps = privacy_metrics['epsilon_budget']
                        st.metric("Œµ (epsilon) Budget", f"{eps:.2f}")

                    with col2:
                        loss = privacy_metrics['privacy_loss_bound']
                        st.metric("Borne de perte de privacy", f"e^{eps:.2f} = {loss:.2f}x")

                    with col3:
                        level = privacy_metrics['privacy_level']
                        if "Forte" in level:
                            st.success(f"‚úÖ {level}")
                        elif "Moyenne" in level:
                            st.warning(f"‚ö†Ô∏è {level}")
                        else:
                            st.error(f"‚ùå {level}")

                    st.markdown("---")

                    if 'flip_probability' in privacy_metrics:
                        st.markdown("### üé≤ EdgeFlip - Param√®tres de Randomisation")
                        col1, col2 = st.columns(2)

                        with col1:
                            flip_prob = privacy_metrics['flip_probability']
                            st.metric("Probabilit√© de flip", f"{flip_prob:.3f}")

                        with col2:
                            expected_noise = privacy_metrics['expected_noise_edges']
                            st.metric("Ar√™tes bruit√©es (attendu)", expected_noise)

                elif 'k_candidates' in privacy_metrics:
                    # Probabilistic
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.metric("k graphes candidats", privacy_metrics['k_candidates'])

                    with col2:
                        st.metric("Œµ tol√©rance", f"{privacy_metrics['epsilon_tolerance']:.2f}")

                    with col3:
                        entropy = privacy_metrics['min_entropy']
                        st.metric("Entropie minimale", f"{entropy:.2f}")

                    st.markdown("---")
                    confusion = privacy_metrics['confusion_factor']
                    st.info(f"**Facteur de confusion** : {confusion} graphes plausibles")

                elif 'min_cluster_size' in privacy_metrics:
                    # Generalization
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.metric("Taille min. cluster", int(privacy_metrics['min_cluster_size']))

                    with col2:
                        st.metric("Taille moy. cluster", f"{privacy_metrics['avg_cluster_size']:.1f}")

                    with col3:
                        max_priv = privacy_metrics['max_privacy']
                        st.metric("Prob. max r√©-identification", f"{max_priv:.3f}")

                st.markdown("---")

                # Garanties globales
                guarantees = calculate_privacy_guarantees(G_orig, G_anon, st.session_state.method_key, method_params)

                if guarantees:
                    st.markdown("### üìã Garanties D√©taill√©es")

                    with st.expander("Voir toutes les garanties"):
                        for key, value in guarantees.items():
                            st.text(f"{key}: {value}")

            else:
                st.info("Aucune m√©trique de privacy sp√©cifique pour cette m√©thode")

        with tab5:
            st.markdown("## üéØ Simulations d'Attaques R√©elles")

            st.markdown("""
            Cette section simule des attaques de **r√©-identification** sur le graphe anonymis√©.
            Ces simulations montrent concr√®tement si un adversaire peut retrouver des n≈ìuds sp√©cifiques.
            """)

            st.markdown("---")

            # S√©lection du n≈ìud cible
            st.markdown("### üéØ Configuration de l'Attaque")

            col1, col2 = st.columns(2)

            with col1:
                target_node = st.number_input(
                    "N≈ìud cible √† retrouver",
                    min_value=0,
                    max_value=G_orig.number_of_nodes()-1,
                    value=0,
                    help="Le n≈ìud que l'adversaire essaie de r√©-identifier"
                )

            with col2:
                attack_type = st.selectbox(
                    "Type d'attaque",
                    ["Degree Attack", "Subgraph Attack (Triangles)"]
                )

            st.markdown("---")

            if st.button("üöÄ Lancer l'Attaque"):
                st.markdown("### üìä R√©sultats de l'Attaque")

                with st.spinner("Simulation en cours..."):
                    if attack_type == "Degree Attack":
                        results = simulate_degree_attack(G_orig, G_anon, target_node)
                    else:
                        results = simulate_subgraph_attack(G_orig, G_anon, target_node)

                if results['success']:
                    st.error("### ‚ö†Ô∏è Attaque R√©ussie !")
                    st.markdown(results['explanation'])

                    st.markdown(f"**N≈ìud r√©-identifi√©** : {results.get('re_identified_node', 'N/A')}")

                else:
                    st.success("### ‚úÖ Attaque √âchou√©e / Partiellement R√©ussie")
                    st.markdown(results['explanation'])

                st.markdown("---")
                st.markdown("### üìà D√©tails Techniques")

                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("**N≈ìud cible** :")
                    st.info(f"N≈ìud {target_node}")

                    if 'target_degree' in results:
                        st.markdown("**Degr√© du n≈ìud** :")
                        st.info(f"Degr√© = {results['target_degree']}")

                    if 'target_triangles' in results:
                        st.markdown("**Triangles** :")
                        st.info(f"{results['target_triangles']} triangles")

                with col2:
                    st.markdown("**Candidats trouv√©s** :")
                    if results['candidates']:
                        st.info(f"{len(results['candidates'])} n≈ìuds : {results['candidates'][:10]}")
                    else:
                        st.info("Aucun candidat")

                    if len(results['candidates']) > 1:
                        prob_success = 1 / len(results['candidates'])
                        st.markdown("**Probabilit√© de succ√®s** :")
                        st.warning(f"{prob_success*100:.1f}%")

            st.markdown("---")

            # Section √©ducative
            with st.expander("üìö En savoir plus sur ces attaques"):
                st.markdown("""
                ### Degree Attack (Attaque par Degr√©)

                L'adversaire conna√Æt le degr√© (nombre de connexions) du n≈ìud cible et cherche
                dans le graphe anonymis√© tous les n≈ìuds ayant ce degr√©.

                **Protection** :
                - k-degree anonymity garantit au moins k n≈ìuds par degr√©
                - Randomisation modifie les degr√©s
                - Differential Privacy ajoute du bruit

                ### Subgraph Attack (Attaque par Sous-graphe)

                L'adversaire conna√Æt la structure locale autour du n≈ìud (ex: triangles, motifs).
                Cette attaque est plus puissante car elle exploite plus d'information.

                **Protection** :
                - Generalization d√©truit les motifs locaux
                - Differential Privacy ajoute/supprime des triangles fictifs
                - Randomisation casse certains motifs
                """)

        with tab6:
            st.markdown(f"## üõ°Ô∏è Attaques et Garanties : {current_method['name']}")

            method_details = ATTACKS_AND_GUARANTEES.get(st.session_state.method_key, {})

            if method_details:
                # Attaques prot√©g√©es
                st.markdown("### ‚úÖ Attaques contre lesquelles la m√©thode prot√®ge")
                attacks_protected = method_details.get('attacks_protected', [])
                for attack in attacks_protected:
                    with st.expander(f"üõ°Ô∏è {attack['name']}", expanded=False):
                        st.markdown(attack['description'])

                # Attaques vuln√©rables
                st.markdown("---")
                st.markdown("### ‚ö†Ô∏è Vuln√©rabilit√©s et Limitations")
                attacks_vulnerable = method_details.get('attacks_vulnerable', [])
                for attack in attacks_vulnerable:
                    with st.expander(f"üö® {attack['name']}", expanded=False):
                        st.markdown(attack['description'])

                # Avantages
                st.markdown("---")
                st.markdown("### ‚úÖ Avantages de la M√©thode")
                advantages = method_details.get('advantages', [])
                for adv in advantages:
                    st.markdown(adv)

                # Inconv√©nients
                st.markdown("---")
                st.markdown("### ‚ùå Inconv√©nients et Limitations")
                disadvantages = method_details.get('disadvantages', [])
                for dis in disadvantages:
                    st.markdown(dis)

                # Exemple Karate
                st.markdown("---")
                st.markdown("### ü•ã Exemple Concret : Graphe Karate Club")
                karate_example = method_details.get('karate_example', '')
                if karate_example:
                    st.markdown(karate_example)
                else:
                    st.info("Exemple √† venir pour cette m√©thode.")
            else:
                st.warning("Informations d√©taill√©es non disponibles pour cette m√©thode.")

        with tab7:
            st.markdown("## üìö Dictionnaire des Attaques de R√©-Identification")

            st.markdown("""
            Ce dictionnaire pr√©sente **toutes les attaques connues** contre les graphes anonymis√©s,
            avec des exemples concrets et des explications d√©taill√©es.
            """)

            st.markdown("---")

            # Liste des attaques
            attack_names = [ATTACKS_DICTIONARY[k]['name'] for k in ATTACKS_DICTIONARY.keys()]

            selected_attack_name = st.selectbox(
                "Choisir une attaque √† explorer",
                attack_names
            )

            # Trouver l'attaque correspondante
            selected_attack_key = list(ATTACKS_DICTIONARY.keys())[attack_names.index(selected_attack_name)]
            attack = ATTACKS_DICTIONARY[selected_attack_key]

            st.markdown(f"### {attack['name']}")

            col1, col2 = st.columns([2, 1])

            with col1:
                with st.expander("üìù Description de l'Attaque", expanded=True):
                    st.markdown(attack['description'])

                with st.expander("üí° Exemple Concret"):
                    st.markdown(attack['example'])

            with col2:
                st.markdown("**‚ö†Ô∏è S√©v√©rit√©**")
                severity = attack['severity']
                if "Tr√®s √©lev√©e" in severity or "√âlev√©e" in severity:
                    st.error(severity)
                elif "Moyenne" in severity:
                    st.warning(severity)
                else:
                    st.info(severity)

                st.markdown("**üõ°Ô∏è Protection**")
                st.success(attack['protection'])

            st.markdown("---")

            # Exemples concrets sur Karate Club
            st.markdown("### ü•ã Exemples Concrets sur Karate Club")

            example_keys = list(CONCRETE_ATTACK_EXAMPLES.keys())

            for example_key in example_keys:
                example = CONCRETE_ATTACK_EXAMPLES[example_key]

                with st.expander(f"üìñ {example['title']}"):
                    st.markdown(f"**Sc√©nario** : {example['scenario']}")

                    st.markdown("**√âtapes de l'attaque** :")
                    for step in example['steps']:
                        st.markdown(f"- {step}")

                    st.markdown("---")
                    st.markdown("**Taux de Succ√®s** :")

                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.metric("Sans protection", example.get('success_rate_no_protection', 'N/A'))

                    with col2:
                        if 'success_rate_k_anonymity' in example:
                            st.metric("Avec k-anonymity", example['success_rate_k_anonymity'])
                        elif 'success_rate_randomization' in example:
                            st.metric("Avec randomization", example['success_rate_randomization'])

                    with col3:
                        if 'success_rate_differential_privacy' in example:
                            st.metric("Avec Diff. Privacy", example['success_rate_differential_privacy'])
                        elif 'success_rate_generalization' in example:
                            st.metric("Avec Generalization", example['success_rate_generalization'])

                    if 'code_simulation' in example:
                        with st.expander("üíª Code de Simulation"):
                            st.code(example['code_simulation'], language='python')

        with tab8:
            st.markdown("## üîç Dictionnaire des Propri√©t√©s de Graphes")

            st.markdown("""
            Ce dictionnaire explique **toutes les propri√©t√©s de graphes** utilis√©es en anonymisation,
            leur importance pour l'utilit√©, et leur risque pour la privacy.
            """)

            st.markdown("---")

            # Liste des propri√©t√©s
            property_names = [GRAPH_PROPERTIES[k]['name'] for k in GRAPH_PROPERTIES.keys()]

            selected_property_name = st.selectbox(
                "Choisir une propri√©t√© √† explorer",
                property_names
            )

            # Trouver la propri√©t√© correspondante
            selected_property_key = list(GRAPH_PROPERTIES.keys())[property_names.index(selected_property_name)]
            prop = GRAPH_PROPERTIES[selected_property_key]

            st.markdown(f"### {prop['name']}")

            col1, col2 = st.columns(2)

            with col1:
                with st.expander("üìù D√©finition", expanded=True):
                    st.markdown(prop['definition'])

                with st.expander("üî¢ Formule"):
                    st.code(prop['formula'], language='text')

                with st.expander("üí° Exemple"):
                    st.info(prop['example'])

            with col2:
                st.markdown("**üìä Importance pour l'Utilit√©**")
                importance = prop['utility_importance']
                if "Critique" in importance or "√âlev√©e" in importance:
                    st.success(importance)
                else:
                    st.info(importance)

                st.markdown("**‚ö†Ô∏è Risque pour la Privacy**")
                risk = prop['privacy_risk']
                if "√âlev√©" in risk:
                    st.error(risk)
                elif "Moyen" in risk:
                    st.warning(risk)
                else:
                    st.success(risk)

            st.markdown("---")

            # Calcul des propri√©t√©s sur le graphe actuel
            if isinstance(G_anon, nx.Graph):
                st.markdown("### üìä Valeurs pour le Graphe Actuel")

                try:
                    if selected_property_key == 'degree':
                        degrees = dict(G_anon.degree())
                        st.metric("Degr√© moyen", f"{np.mean(list(degrees.values())):.2f}")
                        st.metric("Degr√© max", max(degrees.values()))

                    elif selected_property_key == 'clustering_coefficient':
                        clustering = nx.average_clustering(G_anon)
                        st.metric("Coefficient de clustering moyen", f"{clustering:.3f}")

                    elif selected_property_key == 'density':
                        density = nx.density(G_anon)
                        st.metric("Densit√©", f"{density:.3f}")

                    elif selected_property_key == 'diameter':
                        if nx.is_connected(G_anon):
                            diameter = nx.diameter(G_anon)
                            st.metric("Diam√®tre", diameter)
                        else:
                            st.info("Graphe non connexe, diam√®tre non d√©fini")

                    elif selected_property_key == 'average_path_length':
                        if nx.is_connected(G_anon):
                            apl = nx.average_shortest_path_length(G_anon)
                            st.metric("Longueur moyenne des chemins", f"{apl:.2f}")
                        else:
                            st.info("Graphe non connexe, calcul√© sur la plus grande composante")

                except Exception as e:
                    st.warning(f"Calcul non disponible pour ce graphe")

    else:
        st.info("üëà S√©lectionnez une m√©thode et cliquez sur 'Anonymiser le Graphe' pour commencer")

        # Afficher un aper√ßu du graphe original
        st.markdown("### üìä Aper√ßu du Graphe Original")

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("N≈ìuds", G.number_of_nodes())
        with col2:
            st.metric("Ar√™tes", G.number_of_edges())
        with col3:
            st.metric("Degr√© Moyen", f"{sum(d for n, d in G.degree()) / G.number_of_nodes():.2f}")

        fig, ax = plt.subplots(figsize=(10, 8))
        pos = nx.spring_layout(G, seed=42, k=0.5, iterations=50)
        nx.draw_networkx_nodes(G, pos, ax=ax, node_color='lightblue', node_size=500, alpha=0.9)
        nx.draw_networkx_edges(G, pos, ax=ax, edge_color='gray', width=1.5, alpha=0.6)
        nx.draw_networkx_labels(G, pos, ax=ax, font_size=8, font_weight='bold')
        ax.set_title('Graphe Original', fontsize=16, fontweight='bold')
        ax.axis('off')
        st.pyplot(fig)


if __name__ == "__main__":
    main()
