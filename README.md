# DÃ©monstration d'Anonymisation de Graphes Sociaux

Application de dÃ©monstration basÃ©e sur la thÃ¨se **"Anonymisation de Graphes Sociaux"** par **NGUYEN Huu-Hiep** (UniversitÃ© de Lorraine, 2016).

## ğŸ“š Contexte de la ThÃ¨se

Cette thÃ¨se traite de la protection de la vie privÃ©e dans les rÃ©seaux sociaux lors de la publication de graphes. Elle identifie et catÃ©gorise **5 types principaux de mÃ©thodes d'anonymisation** :

### 1. Anonymisation par Randomisation ğŸ²

**Principe** : Perturber la structure du graphe en ajoutant, supprimant ou Ã©changeant des arÃªtes de maniÃ¨re alÃ©atoire.

**MÃ©thodes implÃ©mentÃ©es** :
- **Random Add/Del** : Ajoute k fausses arÃªtes puis supprime k vraies arÃªtes
- **Random Switch** : Ã‰change des paires d'arÃªtes pour prÃ©server les degrÃ©s des nÅ“uds

**Avantages** :
- Simple Ã  implÃ©menter
- PrÃ©servation possible de certaines propriÃ©tÃ©s (degrÃ©s avec Random Switch)

**InconvÃ©nients** :
- Pas de garantie formelle de privacy
- Peut dÃ©grader significativement l'utilitÃ© du graphe

### 2. K-Anonymisation ğŸ”’

**Principe** : Assurer que chaque nÅ“ud est indistinguable d'au moins k-1 autres nÅ“uds en termes de propriÃ©tÃ©s structurelles.

**MÃ©thode implÃ©mentÃ©e** :
- **k-degree anonymity** : Garantit que chaque degrÃ© apparaÃ®t au moins k fois

**Avantages** :
- Garantie formelle contre les attaques basÃ©es sur les degrÃ©s
- ContrÃ´le du niveau d'anonymat via le paramÃ¨tre k

**InconvÃ©nients** :
- NÃ©cessite l'ajout/suppression dÃ©terministe d'arÃªtes
- Peut Ãªtre coÃ»teux en calcul (NP-difficile dans le cas gÃ©nÃ©ral)

### 3. Anonymisation par GÃ©nÃ©ralisation ğŸŒ

**Principe** : Regrouper les nÅ“uds en "super-nÅ“uds" et les arÃªtes en "super-arÃªtes", crÃ©ant ainsi une vue agrÃ©gÃ©e du graphe.

**MÃ©thode implÃ©mentÃ©e** :
- **Clustering en super-nodes** : Groupe les nÅ“uds en clusters de taille â‰¥ k

**Avantages** :
- RÃ©duction significative de la taille du graphe publiÃ©
- Protection forte de l'identitÃ© des nÅ“uds individuels

**InconvÃ©nients** :
- Perte importante d'information structurelle
- Difficile de trouver le partitionnement optimal

### 4. Approches Probabilistes ğŸ¯

**Principe** : Assigner des probabilitÃ©s d'existence aux arÃªtes, crÃ©ant un "graphe incertain".

**MÃ©thode implÃ©mentÃ©e** :
- **(k,Îµ)-obfuscation** : Ajoute des arÃªtes potentielles avec des probabilitÃ©s contrÃ´lÃ©es

**Avantages** :
- ModÃ©lisation explicite de l'incertitude
- Bon compromis privacy/utilitÃ©
- Permet l'Ã©chantillonnage de graphes compatibles

**InconvÃ©nients** :
- ComplexitÃ© de l'Ã©chantillonnage
- NÃ©cessite des algorithmes adaptÃ©s aux graphes probabilistes

### 5. Privacy DiffÃ©rentielle ğŸ›¡ï¸

**Principe** : Garantir mathÃ©matiquement que la prÃ©sence ou l'absence d'une arÃªte (ou d'un nÅ“ud) n'affecte pas significativement la sortie de l'algorithme.

**MÃ©thodes implÃ©mentÃ©es** :
- **EdgeFlip** : Applique le Randomized Response Technique (inverse chaque arÃªte avec probabilitÃ© Îµ-dÃ©pendante)
- **MÃ©canisme de Laplace** : Ajoute du bruit Laplacien pour dÃ©cider de l'inclusion des arÃªtes

**Avantages** :
- Garanties thÃ©oriques rigoureuses (Îµ-differential privacy)
- ComposabilitÃ© des mÃ©canismes
- Pas d'hypothÃ¨ses sur les connaissances de l'attaquant

**InconvÃ©nients** :
- Peut nÃ©cessiter beaucoup de bruit (faible Îµ = haute privacy = basse utilitÃ©)
- ComplexitÃ© quadratique pour certaines mÃ©thodes

## ğŸ® Utilisation

### Installation des dÃ©pendances

```bash
pip install -r requirements.txt
```

### ExÃ©cution de la dÃ©monstration

```bash
python graph_anonymization_demo.py
```

Cette commande :
1. Charge le graphe **Karate Club** de Zachary (34 nÅ“uds, 78 arÃªtes)
2. Applique les 7 variantes des 5 mÃ©thodes d'anonymisation
3. GÃ©nÃ¨re 3 fichiers de visualisation :
   - `graph_anonymization_comparison.png` : Comparaison visuelle des graphes
   - `degree_distributions.png` : Distributions des degrÃ©s
   - `metrics_comparison.png` : MÃ©triques quantitatives

## ğŸ“Š MÃ©triques Ã‰valuÃ©es

L'application compare plusieurs mÃ©triques entre le graphe original et les graphes anonymisÃ©s :

- **Nombre d'arÃªtes** : Mesure les modifications structurelles
- **DegrÃ© moyen** : Indique la prÃ©servation de la connectivitÃ©
- **Coefficient de clustering** : Ã‰value la prÃ©servation des communautÃ©s
- **DensitÃ©** : Ratio arÃªtes existantes / arÃªtes possibles

## ğŸ” Le Graphe Karate Club

Le graphe de Zachary est un rÃ©seau social classique en analyse de rÃ©seaux :
- **34 nÅ“uds** : Membres d'un club de karatÃ©
- **78 arÃªtes** : Relations sociales entre les membres
- **2 communautÃ©s** : ReflÃ¨te une scission rÃ©elle du club

C'est un graphe de rÃ©fÃ©rence pour tester les algorithmes de dÃ©tection de communautÃ©s et d'anonymisation.

## ğŸ“ RÃ©fÃ©rences

**ThÃ¨se** : "Anonymisation de Graphes Sociaux" (Social Graph Anonymization)
**Auteur** : NGUYEN Huu-Hiep
**Institution** : UniversitÃ© de Lorraine, LORIA
**Directeurs** : Abdessamad Imine, MichaÃ«l Rusinowitch
**AnnÃ©e** : 2016

### Publications clÃ©s mentionnÃ©es dans la thÃ¨se :

1. **Randomisation** : Ying & Wu (2008, 2011), Bonchi et al. (2011)
2. **K-anonymity** : Liu & Terzi (2008), Zhou & Pei (2008), Zou et al. (2009)
3. **GÃ©nÃ©ralisation** : Hay et al. (2008), Campan & Truta (2008)
4. **Probabiliste** : Boldi et al. (2012), Mittal et al. (2013)
5. **Differential Privacy** : Dwork (2011), Sala et al. (2011), Xiao et al. (2014)

## ğŸ’¡ Pour votre exposÃ©

### Points clÃ©s Ã  prÃ©senter :

1. **Motivation** : Pourquoi l'anonymisation naÃ¯ve (suppression des IDs) ne suffit pas
   - Attaques par rÃ©-identification basÃ©es sur les degrÃ©s
   - Exemple du graphe Ã  13 nÅ“uds (Fig. 1.1 de la thÃ¨se)

2. **Trade-off Privacy/Utility** : Plus on protÃ¨ge, plus on distord
   - Visualiser ce trade-off avec vos rÃ©sultats

3. **Ã‰volution des approches** :
   - MÃ©thodes ad-hoc (randomisation) â†’ Garanties formelles (k-anonymity) â†’ Privacy diffÃ©rentielle

4. **Applications pratiques** :
   - Publication de donnÃ©es pour la recherche
   - Partage entre organisations
   - Open data de rÃ©seaux sociaux

### Structure suggÃ©rÃ©e pour l'exposÃ© :

1. **Introduction** (5 min)
   - Contexte : Big Data et rÃ©seaux sociaux
   - ProblÃ¨me : Privacy vs UtilitÃ©

2. **Les 5 types de mÃ©thodes** (15 min)
   - Pour chaque type : principe, exemple visuel, avantages/inconvÃ©nients

3. **DÃ©monstration** (10 min)
   - Montrer les visualisations gÃ©nÃ©rÃ©es
   - Comparer les mÃ©triques

4. **Conclusion** (5 min)
   - Ã‰tat de l'art actuel
   - DÃ©fis restants (scalabilitÃ©, nouvelles attaques, etc.)

## ğŸ“ˆ Extensions possibles

- Ajouter d'autres graphes de test (Facebook, Email-Eu-core, etc.)
- ImplÃ©menter des mÃ©triques de privacy (re-identification rate, incorrectness)
- Ajouter des visualisations de communautÃ©s
- Tester sur des graphes de diffÃ©rentes tailles
- ImplÃ©menter des attaques pour quantifier la privacy

## ğŸ› ï¸ Structure du code

```
graph_anonymization_demo.py
â”œâ”€â”€ GraphAnonymizer : Classe principale contenant les 5 mÃ©thodes
â”‚   â”œâ”€â”€ random_add_del()
â”‚   â”œâ”€â”€ random_switch()
â”‚   â”œâ”€â”€ k_degree_anonymity()
â”‚   â”œâ”€â”€ generalization()
â”‚   â”œâ”€â”€ probabilistic_obfuscation()
â”‚   â”œâ”€â”€ differential_privacy_edgeflip()
â”‚   â””â”€â”€ differential_privacy_laplace()
â”‚
â””â”€â”€ GraphVisualizer : Classe pour les visualisations
    â”œâ”€â”€ plot_graph_comparison()
    â”œâ”€â”€ plot_degree_distribution()
    â””â”€â”€ plot_metrics_comparison()
```

## â“ Questions pour l'exposÃ©

PrÃ©parez-vous Ã  rÃ©pondre Ã  :
- Quelle mÃ©thode choisir selon le cas d'usage ?
- Comment mesurer concrÃ¨tement la "privacy" ?
- Quelle est la diffÃ©rence entre edge-DP et node-DP ?
- Comment les graphes probabilistes sont-ils utilisÃ©s en pratique ?
- Y a-t-il des alternatives Ã  la differential privacy ?

Bon exposÃ© ! ğŸ‰
