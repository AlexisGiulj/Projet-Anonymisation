# Application Interactive d'Anonymisation de Graphes Sociaux

Application web interactive bas√©e sur la th√®se **"Anonymisation de Graphes Sociaux"** par **NGUYEN Huu-Hiep** (Universit√© de Lorraine, 2016).

## üåü Caract√©ristiques

- **Interface Streamlit intuitive** : Visualisation et interaction en temps r√©el
- **Th√®se PDF int√©gr√©e** : R√©f√©rences acad√©miques directement dans l'application
- **7 m√©thodes d'anonymisation** impl√©ment√©es selon la th√®se
- **M√©triques d√©taill√©es** : Privacy, utilit√©, et analyse comparative
- **Visualisations interactives** : Graphes, distributions, m√©triques

## üìö Contexte de la Th√®se

Cette th√®se traite de la protection de la vie priv√©e dans les r√©seaux sociaux lors de la publication de graphes. Elle identifie et cat√©gorise **5 types principaux de m√©thodes d'anonymisation** :

### 1. Anonymisation par Randomisation üé≤

**Principe** : Perturber la structure du graphe en ajoutant, supprimant ou √©changeant des ar√™tes de mani√®re al√©atoire.

**M√©thodes impl√©ment√©es** :
- **Random Add/Del** : Ajoute k fausses ar√™tes puis supprime k vraies ar√™tes
- **Random Switch** : √âchange des paires d'ar√™tes pour pr√©server les degr√©s des n≈ìuds

**Avantages** :
- Simple √† impl√©menter
- Pr√©servation possible de certaines propri√©t√©s (degr√©s avec Random Switch)

**Inconv√©nients** :
- Pas de garantie formelle de privacy
- Peut d√©grader significativement l'utilit√© du graphe

### 2. K-Anonymisation üîí

**Principe** : Assurer que chaque n≈ìud est indistinguable d'au moins k-1 autres n≈ìuds en termes de propri√©t√©s structurelles.

**M√©thode impl√©ment√©e** :
- **k-degree anonymity** : Garantit que chaque degr√© appara√Æt au moins k fois

**Formule** : $|\{v \in V : \deg(v) = d\}| \geq k \quad \forall d$

**Avantages** :
- Garantie formelle contre les attaques bas√©es sur les degr√©s
- Contr√¥le du niveau d'anonymat via le param√®tre k

**Inconv√©nients** :
- N√©cessite l'ajout/suppression d√©terministe d'ar√™tes
- NP-difficile dans le cas g√©n√©ral

### 3. Anonymisation par G√©n√©ralisation üåê

**Principe** : Regrouper les n≈ìuds en "super-n≈ìuds" et les ar√™tes en "super-ar√™tes", cr√©ant ainsi une vue agr√©g√©e du graphe.

**M√©thode impl√©ment√©e** :
- **Clustering en super-nodes** : Utilise Label Propagation puis ajuste pour garantir $|C_i| \geq k$

**Algorithme** :
1. Label Propagation pour d√©tecter les communaut√©s naturelles
2. Fusion/division des clusters pour respecter la contrainte de taille minimale

**Avantages** :
- R√©duction significative de la taille du graphe publi√©
- Protection forte de l'identit√© des n≈ìuds individuels

**Inconv√©nients** :
- Perte importante d'information structurelle
- Difficile de trouver le partitionnement optimal

### 4. Approches Probabilistes üéØ

**Principe** : Assigner des probabilit√©s d'existence aux ar√™tes, cr√©ant un "graphe incertain".

**M√©thodes impl√©ment√©es** :

#### (k,Œµ)-obfuscation (Boldi et al. 2012)
Impl√©mentation conforme √† l'algorithme original de Boldi et al. utilisant une **distribution normale tronqu√©e** $R_\sigma$ sur $[0,1]$.

**Algorithme de Construction** :
1. Pour chaque n≈ìud, identifier les k voisins candidats
2. Assigner des probabilit√©s via distribution normale tronqu√©e centr√©e
3. Garantir l'entropie minimale : $H(N_k(v)) \geq \log(k) - \varepsilon$

**‚ö†Ô∏è Limitation connue** : Vuln√©rable au threshold attack (voir th√®se p.75)

#### MaxVar (Variance Maximizing Scheme)
Solution au threshold attack via optimisation quadratique.

**Programme** : $\min \sum_i p_i^2$ sous contrainte $\sum_{v \in N(u)} p_{uv} = \deg(u)$

**Avantages** :
- R√©siste au threshold attack
- Probabilit√©s dispers√©es (pas de concentration en 0/1)
- Ar√™tes "nearby" (distance 2) pour minimiser la distance d'√©dition

**Inconv√©nients** :
- Complexit√© $O(m^2)$

### 5. Privacy Diff√©rentielle üõ°Ô∏è

**Principe** : Garantir math√©matiquement que la pr√©sence ou l'absence d'une ar√™te n'affecte pas significativement la sortie.

**D√©finition** : $P[\mathcal{A}(G) = O] \leq e^\varepsilon \cdot P[\mathcal{A}(G') = O]$

**M√©thodes impl√©ment√©es** :
- **EdgeFlip** : Randomized Response Technique avec $s = \frac{2}{e^\varepsilon + 1}$
- **Laplace** : M√©canisme de Laplace avec bruit $\sim \text{Lap}(\Delta f / \varepsilon)$

**Avantages** :
- Garanties th√©oriques rigoureuses (Œµ-differential privacy)
- Composabilit√© des m√©canismes
- Pas d'hypoth√®ses sur les connaissances de l'attaquant

**Inconv√©nients** :
- Trade-off privacy/utilit√© : faible Œµ = haute privacy = basse utilit√©
- Complexit√© $O(n^2)$ pour certaines m√©thodes

## üéÆ Utilisation

### Installation des d√©pendances

```bash
pip install streamlit networkx matplotlib numpy scipy pandas
```

Ou via requirements.txt :

```bash
pip install -r requirements.txt
```

### Lancement de l'application

```bash
streamlit run graph_anonymization_app.py
```

L'application s'ouvrira dans votre navigateur √† `http://localhost:8501`

### Fonctionnalit√©s de l'interface

1. **S√©lection du graphe** : Karate Club, ou graphes al√©atoires
2. **Choix de la m√©thode** : 7 m√©thodes d'anonymisation disponibles
3. **Configuration des param√®tres** : k, Œµ, nombre d'ar√™tes potentielles, etc.
4. **Visualisation** : Graphes comparatifs avec code couleur pour les probabilit√©s
5. **M√©triques** : Analyse d√©taill√©e de la privacy et de l'utilit√©
6. **R√©f√©rences th√®se** : Liens directs vers les sections pertinentes du PDF

## üìä M√©triques √âvalu√©es

### M√©triques d'Utilit√©

- **Distance d'√©dition** : Nombre d'ar√™tes modifi√©es (ajout√©es + supprim√©es)
- **Degr√© moyen** : Pr√©servation de la connectivit√©
- **Coefficient de clustering** : Pr√©servation des communaut√©s
- **Densit√©** : Ratio ar√™tes existantes / ar√™tes possibles
- **Diam√®tre** : Plus long plus court chemin
- **Corr√©lation des degr√©s** : Similarit√© des distributions de degr√©s

### M√©triques de Privacy

- **k-anonymity** : Nombre minimum d'occurrences de chaque degr√©
- **Variance des probabilit√©s** : R√©sistance au threshold attack (MaxVar)
- **Taux de reconstruction** : Efficacit√© du threshold attack
- **Epsilon** : Budget de differential privacy

## üîç Le Graphe Karate Club

Le graphe de Zachary est un r√©seau social classique en analyse de r√©seaux :
- **34 n≈ìuds** : Membres d'un club de karat√©
- **78 ar√™tes** : Relations sociales entre les membres
- **2 communaut√©s** : Refl√®te une scission r√©elle du club

C'est un graphe de r√©f√©rence pour tester les algorithmes de d√©tection de communaut√©s et d'anonymisation.

## üéì R√©f√©rences

**Th√®se** : "Anonymisation de Graphes Sociaux" (Social Graph Anonymization)
**Auteur** : NGUYEN Huu-Hiep
**Institution** : Universit√© de Lorraine, LORIA
**Directeurs** : Abdessamad Imine, Micha√´l Rusinowitch
**Ann√©e** : 2016

### Publications cl√©s impl√©ment√©es :

1. **Randomisation** : Ying & Wu (2008, 2011), Bonchi et al. (2011)
2. **K-anonymity** : Liu & Terzi (2008), Zhou & Pei (2008)
3. **G√©n√©ralisation** : Hay et al. (2008), Campan & Truta (2008)
4. **Probabiliste** : **Boldi et al. (2012)**, Mittal et al. (2013)
5. **Differential Privacy** : Dwork (2011), Sala et al. (2011)

### R√©f√©rences directes dans la th√®se :

- **p.30-32** : k-Anonymity et k-degree anonymity
- **p.40** : G√©n√©ralisation par super-nodes
- **p.50-52** : Differential Privacy (EdgeFlip)
- **p.70-75** : (k,Œµ)-obfuscation et threshold attack
- **p.80-85** : MaxVar (solution au threshold attack)

## üìà D√©tails d'Impl√©mentation

### Algorithme de Boldi et al. (Distribution Normale Tronqu√©e)

Contrairement √† la formule simplifi√©e $p = 1 - \varepsilon/k$, l'impl√©mentation suit l'algorithme original de Boldi et al. (2012) :

**Distribution $R_\sigma$** : Normale tronqu√©e sur $[0,1]$ avec √©cart-type $\sigma$ calcul√© pour garantir :
$$H(N_k(v)) = -\sum_i p_i \log(p_i) \geq \log(k) - \varepsilon$$

**Processus** :
1. Pour chaque n≈ìud $v$, identifier $N_k(v)$ (k voisins candidats)
2. Tirer $k$ valeurs de $R_\sigma$ et normaliser
3. Assigner ces probabilit√©s normalis√©es aux ar√™tes candidates
4. V√©rifier la contrainte d'entropie

**Avantage** : Distribution plus r√©aliste que la formule uniforme
**Inconv√©nient** : Plus sensible au threshold attack (d'o√π l'importance de MaxVar)

### MaxVar : R√©solution du Threshold Attack

MaxVar r√©sout un programme quadratique pour disperser les probabilit√©s :

```python
# Objectif : minimiser la somme des p_i^2
# Contrainte : somme des probabilit√©s sortantes = degr√© du n≈ìud
# R√©solution : SLSQP (Sequential Least Squares Programming)
```

**R√©sultat** : Probabilit√©s autour de 0.5 au lieu de 0/1, rendant le threshold attack inefficace.

## üõ†Ô∏è Structure du Projet

```
GraphAnonymizationDemo/
‚îú‚îÄ‚îÄ graph_anonymization_app.py      # Application Streamlit principale
‚îú‚îÄ‚îÄ method_details.py                # Documentation attaques & garanties
‚îú‚îÄ‚îÄ definitions_and_attacks.py       # D√©finitions et dictionnaires
‚îú‚îÄ‚îÄ thesis_references.py             # R√©f√©rences vers la th√®se
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îî‚îÄ‚îÄ thesis.pdf                   # Th√®se PDF int√©gr√©e
‚îú‚îÄ‚îÄ requirements.txt                 # D√©pendances Python
‚îî‚îÄ‚îÄ README.md                        # Ce fichier
```

## üí° Utilisation P√©dagogique

### Points cl√©s √† pr√©senter :

1. **Motivation** : Pourquoi l'anonymisation na√Øve (suppression des IDs) ne suffit pas
   - Attaques par r√©-identification bas√©es sur les degr√©s
   - Attaques par connaissance du voisinage

2. **Trade-off Privacy/Utility** : Plus on prot√®ge, plus on distord
   - Visualiser ce trade-off avec les m√©triques de l'application
   - Comparer distance d'√©dition vs garanties de privacy

3. **√âvolution des approches** :
   - M√©thodes ad-hoc (randomisation)
   - ‚Üí Garanties formelles (k-anonymity)
   - ‚Üí Privacy diff√©rentielle (gold standard)

4. **Cas d'usage r√©el** :
   - Publication de donn√©es pour la recherche m√©dicale
   - Partage de graphes sociaux entre organisations
   - Open data de r√©seaux de mobilit√©

### Structure sugg√©r√©e pour pr√©sentation :

1. **Introduction** (5 min)
   - Contexte : Big Data et r√©seaux sociaux
   - Probl√®me : Privacy vs Utilit√©
   - D√©mo rapide de l'application

2. **Les 5 types de m√©thodes** (15 min)
   - Pour chaque type : principe, exemple visuel, avantages/inconv√©nients
   - Focus sur threshold attack et MaxVar

3. **D√©monstration interactive** (10 min)
   - Montrer les visualisations en direct
   - Comparer les m√©triques
   - Tester diff√©rents param√®tres

4. **Conclusion** (5 min)
   - √âtat de l'art actuel
   - D√©fis restants (scalabilit√©, nouvelles attaques, ML-based attacks)

## ‚ùì Questions Fr√©quentes

**Q : Quelle m√©thode choisir selon le cas d'usage ?**
- Privacy maximale : Differential Privacy (EdgeFlip)
- Pr√©servation structure : MaxVar
- Simplicit√© : k-degree anonymity
- R√©duction taille : Generalization

**Q : Pourquoi Boldi et al. au lieu de la formule simplifi√©e ?**
- Distribution normale tronqu√©e plus r√©aliste
- Conforme √† la publication originale
- Meilleure mod√©lisation de l'incertitude

**Q : Diff√©rence entre (k,Œµ)-obf et MaxVar ?**
- (k,Œµ)-obf : Garantit entropie, mais vuln√©rable au seuillage
- MaxVar : Maximise variance, r√©siste au threshold attack

**Q : Comment mesurer concr√®tement la "privacy" ?**
- M√©triques formelles : k-anonymity, Œµ-differential privacy
- M√©triques empiriques : taux de reconstruction, distance d'√©dition
- Simulations d'attaques : degree attack, neighborhood attack

## üìù Licence

Ce projet est d√©velopp√© √† des fins p√©dagogiques bas√© sur la th√®se publique de NGUYEN Huu-Hiep.

## ü§ù Contributions

Les contributions sont les bienvenues ! Pour toute am√©lioration :
1. Fork le projet
2. Cr√©er une branche feature
3. Commit les changements
4. Push et cr√©er une Pull Request
